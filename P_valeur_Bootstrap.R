rm(list=ls())
library(MASS)
library(ggplot2)
library(foreach)
library(doParallel)

### Simulation de trajectoires SMP 
simulate_SMP <- function(n, n_states, P, alpha, dist_type, dist_params, max_transitions) {
  trajectories <- vector("list", n)
  
  for (i in 1:n) {
    states <- numeric(max_transitions)
    times <- numeric(max_transitions)
    states[1] <- sample(1:n_states, 1, prob = alpha) # Ã‰tat initial
    
    for (t in 1:(max_transitions - 1)) {
      states[t + 1] <- sample(1:n_states, 1, prob = P[states[t], ]) # Transition
      
      # Tirage du temps de sÃ©jour selon la distribution spÃ©cifiÃ©e
      if (dist_type == "gamma") {
        times[t] <- rgamma(1, shape = dist_params[states[t], 1],
                           rate = dist_params[states[t], 2])
      } else if (dist_type == "weibull") {
        times[t] <- rweibull(1, shape = dist_params[states[t], 1],
                             scale = dist_params[states[t], 2])
      } else {
        times[t] <- rexp(1, rate = dist_params[states[t], 1])
      }
      
    }
    trajectories[[i]] <- list(states = states, times = times)
  }
  return(trajectories)
}


### Estimation theta ----
estimate_SMP_params <- function(trajectories, n_states, dist_type) {
  # Estimation frÃ©quences initiales
  initial_states <- sapply(trajectories, function(x) x$states[1])
  alpha <- table(factor(initial_states, levels=1:n_states))
  alpha <- alpha/sum(alpha)
  
  # Estimation matrice de transitions
  #on extrait sous forme de vecteur chaque changement de trajectoire
  all_from <- unlist(lapply(trajectories, function(traj) traj$states[-length(traj$states)]))
  all_to   <- unlist(lapply(trajectories, function(traj) traj$states[-1]))
  
  M_from <- diag(n_states)[all_from, , drop = FALSE]
  M_to   <- diag(n_states)[all_to, , drop = FALSE]  
  
  #on utilise le produit matriciel
  transition_counts <- t(M_from) %*% M_to             
  
  P <- transition_counts / rowSums(transition_counts)
  
  # Estimation Ï‰ (MLE par Ã©tat)
  if(dist_type == "gamma" || dist_type == "weibull") {
    dist_params <- matrix(0, nrow = n_states, ncol = 2)
  } else {
    dist_params <- matrix(0, nrow = n_states, ncol = 1)
  }
  
  for (state in 1:n_states) {
    durations <- unlist(lapply(trajectories, function(traj) {
      idx <- which(traj$states[-length(traj$states)] == state)
      if(length(idx) > 0) return(traj$times[idx]) 
      else return(NULL)
    }))
    if (length(durations) > 1) {
      if(dist_type == "gamma") {
        fit <- fitdistr(durations, "gamma", start=list(shape=1, rate=1))
        dist_params[state, ] <- c(fit$estimate["shape"], fit$estimate["rate"])
      } else if(dist_type == "weibull") {
        fit <- fitdistr(durations, "weibull", start=list(shape=1, scale=1))
        dist_params[state, ] <- c(fit$estimate["shape"], fit$estimate["scale"])
      } else {
        fit <- fitdistr(durations, "exponential", start=list(rate=1))
        dist_params[state, ] <- fit$estimate["rate"]
      }
    }
  }
  return(list(alpha=alpha, P=P, dist_params=dist_params))
}





### Log-vraisemblance ----
log_likelihood <- function(params, trajectories, dist_type) {
  alpha <- params$alpha
  P <- params$P
  dist_params <- params$dist_params
  logL <- 0
  epsilon <- 1e-10
  
  for (traj in trajectories) {
    states <- traj$states
    times <- traj$times
    
    logL <- logL + log(max(alpha[states[1]], epsilon))
    
    from <- states[-length(states)]
    to   <- states[-1]
    durations <- times[-length(times)]
    
    log_transi <- log(pmax(P[cbind(from, to)], epsilon))
    log_transi[!is.finite(log_transi)] <- log(epsilon)
    logL <- logL + sum(log_transi)
    
    valid <- !is.na(from) & from >= 1 & from <= nrow(dist_params)
    
    if (any(valid)) { #plein de sÃ©curitÃ©s pour que le code puisse tourner
      if (dist_type == "gamma") {
        dens <- dgamma(durations, shape = dist_params[from, 1], rate = dist_params[from, 2])
        log_dens <- log(pmax(dens, epsilon))
        log_dens[!is.finite(log_dens)] <- log(epsilon)
        logL <- logL + sum(log_dens)
        
      } else if (dist_type == "weibull") {
        dens <- dweibull(durations, shape = dist_params[from, 1], scale = dist_params[from, 2])
        log_dens <- log(pmax(dens, epsilon))
        log_dens[!is.finite(log_dens)] <- log(epsilon)
        logL <- logL + sum(log_dens)
        
      } else if (dist_type == "exponential") {
        dens <- dexp(durations, rate = dist_params[from, 1])
        log_dens <- log(pmax(dens, epsilon))
        log_dens[!is.finite(log_dens)] <- log(epsilon)
        logL <- logL + sum(log_dens)
      }
    }
  }
  return(logL)
}



### Ratio de vraisemblance ----
compute_LR <- function(trajectories1, trajectories2, n_states, dist_type) {
  # Estimation sous H0 (donnÃ©es regroupÃ©es)
  mle_H0 <- estimate_SMP_params(c(trajectories1, trajectories2), n_states, dist_type)
  
  # Estimation sous H1 (donnÃ©es sÃ©parÃ©es)
  mle_H1_t1 <- estimate_SMP_params(trajectories1, n_states, dist_type)
  mle_H1_t2 <- estimate_SMP_params(trajectories2, n_states, dist_type)
  
  # Calcul des log-vraisemblances
  logL_H0 <- log_likelihood(mle_H0, c(trajectories1, trajectories2), dist_type)
  
  logL_H1 <- log_likelihood(mle_H1_t1, trajectories1, dist_type) + log_likelihood(mle_H1_t2, trajectories2, dist_type)
  
  LR <- exp(logL_H0 - logL_H1)
  return(list(LR = LR, log_LR = log(LR)))
}


### 2) Parametric bootstrap ----
# on vient gÃ©nÃ©rer un Ã©chantillon de trajectoires suivant les paramÃ¨tres du MLE sous H0 :
simulate_SMP_bootstrap <- function(n, n_states, params, dist_type, max_transitions) {
  alpha <- params$alpha
  P <- params$P
  dist_params <- params$dist_params
  
  trajectories <- vector("list", n)
  
  for (i in 1:n) {
    states <- numeric(max_transitions)
    times <- numeric(max_transitions)
    states[1] <- sample(1:n_states, 1, prob = alpha) # Ã‰tat initial
    
    for (t in 1:(max_transitions - 1)) {
      states[t + 1] <- sample(1:n_states, 1, prob = P[states[t], ]) # Transition
      
      # Tirage du temps de sÃ©jour selon la distribution spÃ©cifiÃ©e
      if (dist_type == "gamma") {
        times[t] <- rgamma(1, shape = dist_params[states[t], 1],
                           rate = dist_params[states[t], 2])
      } else if (dist_type == "weibull") {
        times[t] <- rweibull(1, shape = dist_params[states[t], 1],
                             scale = dist_params[states[t], 2])
      } else {
        times[t] <- rexp(1, rate = dist_params[states[t], 1])
      }
      
    }
    trajectories[[i]] <- list(states = states, times = times)
  }
  return(trajectories)
}

#On vient ensuite effectuer R fois ce processus en calculant la statistique de test Ã  chaque fois

parametric_bootstrap <- function(trajectories1, trajectories2, 
                                 n1, n2, n_states, max_transitions, 
                                 dist_type, R, n_cores = parallel::detectCores() - 1) {
  
  # ðŸ“Œ Calcul des paramÃ¨tres du MLE sous H0
  mle_params <- estimate_SMP_params(c(trajectories1, trajectories2), n_states, dist_type)
  
  # ðŸ“Œ Statistique observÃ©e
  T_l <- compute_LR(trajectories1, trajectories2, n_states, dist_type)
  
  # ðŸ“Œ Lancement du cluster
  cl <- parallel::makeCluster(n_cores)
  doParallel::registerDoParallel(cl)
  
  # Export des fonctions + objets nÃ©cessaires dans les workers
  parallel::clusterExport(cl, varlist = c(
    "simulate_SMP_bootstrap", 
    "estimate_SMP_params", 
    "compute_LR",
    "log_likelihood",
    "n1", "n2", "n_states", "max_transitions", "dist_type", "mle_params", "T_l"
  ), envir = environment())  # important d'inclure l'environnement
  
  # SÃ©curitÃ© : si une erreur arrive dans le foreach, on stoppe le cluster proprement
  results <- tryCatch({
    
    foreach::foreach(r = 1:R, .combine = '+', .packages = c("stats","MASS")) %dopar% {
      bootstrap_trajectories1 <- simulate_SMP_bootstrap(n1, n_states, mle_params, dist_type, max_transitions)
      bootstrap_trajectories2 <- simulate_SMP_bootstrap(n2, n_states, mle_params, dist_type, max_transitions)
      
      T_star <- compute_LR(bootstrap_trajectories1, bootstrap_trajectories2, n_states, dist_type)
      
      as.integer(T_star[[2]] <= T_l[[2]])
    }
    
  }, finally = {
    # Stoppe le cluster mÃªme sâ€™il y a une erreur
    parallel::stopCluster(cl)
  })
  
  # ðŸ”¢ Calcul final de la p-valeur
  p_boot <- results / R
  return(p_boot)
}




### Test sur donnÃ©es rÃ©elles ----

#### Data management ----
data <- read.table("C:/Users/rapha/Desktop/MÃ©moire/donnees.txt", 
                   header = TRUE,      # La premiÃ¨re ligne contient les noms de colonnes
                   sep = "\t",         # DÃ©limiteur tabulation
                   quote = "",         # Pas de guillemets pour dÃ©limiter les chaÃ®nes
                   na.strings = "",    # ChaÃ®nes vides comme NA
                   fill = TRUE,        # ComplÃ©ter les lignes trop courtes
                   stringsAsFactors = FALSE)



# Fonction pour transformer les donnÃ©es d'un individu en format semi-markovien
formatage_smp <- function(row) {
  # Extraire les colonnes c1 Ã  c94 qui reprÃ©sentent les Ã©tats mensuels
  colonnes_etats <- paste0("c", 1:94)
  states <- as.numeric(row[colonnes_etats])
  
  # Identifier les changements d'Ã©tat (TRUE quand il y a changement)
  changements <- c(TRUE, states[-1] != states[-length(states)])
  
  # Extraire la sÃ©quence d'Ã©tats uniques (sans rÃ©pÃ©tition d'Ã©tats consÃ©cutifs identiques)
  etats_uniques <- states[changements]
  
  # Calculer les temps de sÃ©jour dans chaque Ã©tat
  times <- as.double(rle(states)$lengths)
  
  # Retourner une liste avec les Ã©tats et les durÃ©es
  return(list(
    states = etats_uniques,
    times = times
  ))
}



#### Fonction de test global ----
test_boostrap <- function(base1, base2, n_states, dist_type){
  
  n1 <- nrow(base1)
  n2 <- nrow(base2)
  n <- n1+n2
  
  trajectoires1 <- list()
  for(i in 1:nrow(base1)) {
    id <- base1$IDENT[i]
    trajectoires1[[as.character(id)]] <- formatage_smp(base1[i,])
  }
  
  trajectoires2 <- list()
  for(i in 1:nrow(base2)) {
    id <- base2$IDENT[i]
    trajectoires2[[as.character(id)]] <- formatage_smp(base2[i,])
  }
  
  likelihood_ratio <- compute_LR(trajectoires1, trajectoires2, n_states, dist_type)
  
  
  return(likelihood_ratio = likelihood_ratio)
}

library(skimr)
skim(data)
#### 2Ã¨me test ----
# tentative de test significatif :
# test entre individus similaires, n'Ã©tant diffÃ©rents que par le fait d'avoir
# eu une mobilitÃ© de commune durant le parcours scolaire ou non (Q31A)
# paramÃ¨tres
n_states <- 9
dist_type <- "weibull"

base_1 <- data[data$Q1==1&data$Q31==11&data$perefr==1&data$merefr==1&data$Q53==3&data$Q52==3&data$Q31A==1,]
base_2 <- data[data$Q1==1&data$Q31==11&data$perefr==1&data$merefr==1&data$Q53==3&data$Q52==3&data$Q31A==2,]
trajectoires_smp1 <- list()
for(i in 1:nrow(data)) {
  id <- base_1$IDENT[i]
  trajectoires_smp1[[as.character(id)]] <- formatage_smp(data[i,])
}
trajectoires_smp2 <- list()
for(i in 1:nrow(data)) {
  id <- base_2$IDENT[i]
  trajectoires_smp2[[as.character(id)]] <- formatage_smp(data[i,])
}



test_boostrap(base_1, base_2, n_states, dist_type)

p_value_2 <- parametric_bootstrap(trajectoires_smp1, trajectoires_smp2, 1400, 330, n_states, 9, dist_type, 1000)







  
