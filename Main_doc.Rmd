---
title: "Master's Thesis"
author: "Paul Rongieras, Valentin Rivet, RaphaÃ«l Capranico"
date: "2025-01-20"
output:
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
subtitle: >
  C. Frascola et al., 2022.
  Based on the article: "Two-Sample Tests for Semi-Markov Processes with 
  Parametric Sojourn Time Distributions: An Application in Sensory Analysis"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## I. Introduction

## II. Model and notations

### 1. Definition of a semi-Markov process

We define $(J_p)_{p \geq 1}$, a homogeneous Markov chain taking values in a finite state space $E$, with $D$ states and so $E = \{1, \ldots, D\}$. We denote its transition matrix $P$ by its generic elements $P_{lj} = \mathbb{P}(J_{p+1} = j \mid J_p = l)$ for all $j \neq l \in E$, and we suppose $P_{jj} = 0$ for all $j \in E$. We also define $(X_p)_{p \geq 1}$, the sequence of sojourn times in the visited states by the chain $(J_p)_{p \geq 1}$. For $j \neq l$, $\Phi_{lj}(t) = \mathbb{P}[X_p \leq t \mid J_p = l, J_{p+1} = j]$ is defined as the cumulative distribution function of the sojourn time given the current state of the chain and its next state.

The process $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process and satisfies the following Markov property for $t \in T = [0, +\infty)$, $j \neq l \in E$: 

$\mathbb{P}[J_{p+1} = j, X_p \leq t \mid J_p = l, J_{p-1}, \ldots, J_1, X_{p-1}, \ldots, X_1] = \mathbb{P}(J_{p+1} = j, X_p \leq t \mid J_p = l)$

as $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process. This can be rewritten as $\mathbb{P}(J_{p+1} = j \mid J_p = l) \cdot \mathbb{P}(X_p \leq t \mid J_{p+1} = j, J_p = l)$, using the formula $(i)$: 
$\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C)$, for any sets $A$, $B$, $C$. Thus: $P_{lj} \cdot \Phi_{lj}(t)$.

Proof of $(i)$: $\mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C) = \frac{\mathbb{P}(A \cap C)}{\mathbb{P}(C)} \cdot \frac{\mathbb{P}(B \cap A \cap C)}{\mathbb{P}(A \cap C)} = \frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)} = \mathbb{P}(A \cap B \mid C).$

The process giving the visited state at each time $t \in T$ is called a semi-Markov process. We then denote $\alpha = (\alpha_1, \ldots, \alpha_D)$ the vector of initial probabilities of the process, where $\alpha_j = \mathbb{P}(J_1 = j)$, $j \in E$.

We suppose that the distribution of the sojourn time is a parametric one, discrete or continuous, depending on a set of parameters denoted by $\omega \in \Omega \subset \mathbb{R}^q$. Thus, the law of a semi-Markov process (SMP) $(J_p, X_p)_{p \geq 1}$ can be characterised with the multidimensional parameter $\theta = (\alpha, P, (\omega_{l,j})_{l \neq j \in E}) \in \Theta$, where $\Theta$ is the parameter space. We denote by $\phi(t, \omega_{l,j})$ the probability (discrete time) or the density function (continuous time) of the distribution of the sojourn times for transitions between states $l$ and $j$, which is characterized by the vector of parameters $\omega = (\omega_{l,j})_{l \neq j \in E}$.

### 2. The Likelihood Given Observed Trajectories

As we consider a testing strategy based on the likelihood ratio $LR$, we have to define the likelihood of one Semi-Markov Process. To this purpose, we distinguish three different observation processes.

#### 2.1. A given number of transitions

\

First, each trajectory $S_i$ is observed during $M_i$ transitions, without censoring for the last sojourn time, so that $S_i = (J_1^{i},X_1^{i},...,J_{M_i}^{i},X_{M_i}^{i},J_{M_i+1}^{i},X_{M_i+1}^{i})$. Therefore, the likelihood corresponding to $S_i$ is equal to:

$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i+1}=J_{M_i+1}^{i},X_{M_i+1} \leq X_{M_i+1}^{i})$$
$$ = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = \mathbb{P}(J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i}|J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$  * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$ * \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}, J_{M_i+2} = j|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = P_{J_{M_i}^{i}J_{M_i+1}^{i}} \phi(X_{M_i}^{i},\omega_{J_{M_i}^{i},J_{M_i+1}^{i}}) * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
$$ = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
by applying Chapman-Kolmogorov repeatedly.

If we suppose that $\forall j \neq l, \omega_{l,j} = \omega_l$, we have the last term that becomes:
$$\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j}) = \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(J_{M_i+2} = j|J_{M_i+1}=J_{M_i+1}^{i}) * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_{M_i+1}=J_{M_i+1}^{i})$$
$$ = 1 * \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}}) = \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$
So in this case, the expression of the likelihood is simplified:
$$\mathcal{L}(S_i;\theta) = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i}}) *\phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$

#### 2.2. A given time for observation

\

The second supposition that we can make is that each sequence $S_i$ is observed over a period $[0,T_i]$ of time, so that the last sojourn time $u_{T_i}^{i}$ is censored. By denoting by $M_i(T_i)$ the number of visited states before instant $T_i$, the sequence $S_i$ is equal to $(J_1^{i},X_1^{i},...,J_{M_i(T_i)}^{i},u_{T_i}^{i})$. $\overline H_{J_{M_i(T_i)}}(t)$ describes the survival function for the last visited state of the trajectory $S_i$. For $l \in E, t>0$, we have:
$$\overline H_l^{i}(t) = \mathbb{P}(X_{M_i(T_i)}^{i}>t|J_{M_i(T_i)}^{i}=l) =1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l)$$
$$=1 -\sum_{\substack{j \in E,\ j \neq l}} \mathbb{P}(X_{M_i(T_i)}^{i} \leq t, J_{M_i(T_i)+1}^{i}=j|J_{M_i(T_i)}^{i}=l)$$
$$ =1 - \sum_{\substack{j \in E,\ j \neq l}} P_{lj} * \phi(t,\omega_{l,j})$$

We can define the likelihood of the trajectory $S_i$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i},X_{M_i(T_i)} \geq u_{T_i}^{i})$$
as the last sojourn time is censored,
$$=\mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i}) * \mathbb{P}(X_{M_i(T_i)} \geq u_{T_i}^{i} |J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i})$$
$$=\alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$$
$$ * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} \mathbb{P}\left( X_{M_i(T_i)} \leq u_{T_i}^{i},\ J_{M_i(T_i)+1}=j\ \middle|\ J_1=J_1^{i}, X_1 \leq X_1^{i}, \ldots, J_{M_i(T_i)}=J_{M_i(T_i)}^{i} \right)  \right)$$
by the result of 2.1.
$$= \alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} P_{J_{M_i(T_i)}^{i}j} \phi(u_{T_i}^{i}, \omega_{J_{M_i(T_i)}^{i}, j}) \right)$$
$$=\alpha_{J_1}^{i} * \left(\prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})\right) * \overline H_{J_{M_i(T_i)}^{i}}(u_{T_i}^{i})$$

We can note that when the sojourn time distribution only depends on the current state $l$, we have $\overline H_l^{i}(t) = 1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l) = 1 - \phi(t, \omega_l)$.

#### 2.3. Observation until absorption

\

If we consider that our processes may have an absorbing state, we suppose that we observe a trajectory $S_i$ until absorption. To simplify, we relabel the states such that the absorbing state is the last state D. It is assumed that the absorbing state can not be reached during the first transition so that $\alpha_D = \mathbb{P}(J_1=D)=0$, and $\Phi_{lj}(t)$ is only defined for $l \in E_{\setminus D},\ j \in E$ and $l \neq j$. By denoting by $M_i(D)$ the number of visited states before absorption, we can write the likelihood of a trajectory $S_i= (J_1^{i},X_1^{i},...,J_{M_i(D)}^{i},X_{M_i(D)}^{i},J_{M_i(D)+1}^{i}=D)$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(D)}=J_{M_i(D)}^{i},X_{M_i(D)} \leq X_{M_i(D)}^{i},J_{M_i(D)+1}=D)$$
$$= \mathbb P (J_{M_i(D)+1}=D, X_{M_i(D)} \leq X_{M_i(D)}^{i} | J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ * \mathbb P (J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i},D}) * \mathbb P (J_{M_i(D)}=J_{M_i(D)}^{i}, X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i} | ...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i}) $$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i}D}) * P_{J_{M_i(D)-1}^{i}J_{M_i(D)}^{i}} * \phi (X_{M_i(D)-1}^{i}, \omega_{J_{M_i(D)-1}^{i},M_{i(D)}^{i}})$$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$= \alpha_{J_1}^{i} * \phi(X_1^{i}, \omega_{J_1^{i},J_2^{i}}) * \left( \prod_{k=2}^{M_i(D)} P_{J_{k-1}^{i}J_k^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) \right) * P_{J_{M_i(D)}^{i}D}$$
by iterating.

To simplify future computations, we write:
$$\mathcal{L}(S_i;\theta) = \mathcal{L_1}(S_i;\alpha) * \mathcal{L_2}(S_i;\omega) * \mathcal{L_3}(S_i;P)$$
with $\mathcal{L_1}(S_i;\alpha) = \alpha_{J_1^{i}}$ ; $\mathcal{L_2}(S_i;\omega)= \prod_{k=1}^{M_i(D)} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$ and $\mathcal{L_3}(S_i;P)= \prod_{k=2}^{M_i(D)+1} P_{J_{k-1}^{i}J_k^{i}}$.

## III. Two samples hypothesis testing

### 1) Global likelihood ratio test

Construction du Likelihood Ratio

- Sous \(H_0\)

Par indÃ©pendance des observations \(S^1\) et \(S^2\), on peut maximiser la vraisemblance :

\[
\max_{\theta \in \Theta} \prod_{i=1}^{n1} l(S_i^1, \theta) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta)
\]

- Sous \(H_1\)

Cela devient :

\[
\max_{\theta_1 \in \Theta_1, \theta_2 \in \Theta_2} \prod_{i=1}^{n1} l(S_i^1, \theta_1) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta_2)
\]

On obtient bien le ratio de vraisemblance :

\[
LR = \frac{\text{vraisemblance sous } H_0}{\text{vraisemblance sous } H_1}
\]

### 2) Asymptotic distribution of -2ln(LR)


Pour calculer la p-valeur de notre test, on va montrer que :

\[
-2\ln(LR) \sim \chi^2(d)
\]



Soit \(\mathcal{l}(\theta)\) la log-vraisemblance, avec :

- \(\hat{\theta}\) : Estimateur du maximum de vraisemblance (MLE) de \(\theta\),
- \(\theta_0\) : Valeur de \(\theta\) sous \(H_0\).

Par dÃ©veloppement en sÃ©rie de Taylor autour de \(\hat{\theta}\) :

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta})
\]

Par dÃ©finition du MLE, on sait que :

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

Cela implique que :

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2}\right) (\theta_0 - \hat{\theta})
\]

Ou encore :

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]


Par la loi des grands nombres :

\[
\frac{1}{n} \frac{\partial^2 \mathcal{L}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{L}}{\partial \theta^2}\right]
\]

Alors, en utilisant l'information de Fisher \(I_{\theta_0}\) :

\[
\frac{\partial^2 \mathcal{L}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Donc :

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta})
\]


Sous \(H_0\), on sait que :

\[
\sqrt{n} I_{\theta_0}^{1/2} (\theta_0 - \hat{\theta}) \sim \mathcal{N}(0, I)
\]

Cela implique que :

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

oÃ¹ \(d\) est la diffÃ©rence entre les paramÃ¨tres estimÃ©s sous \(H_1\) et \(H_0\).


La p-valeur est alors donnÃ©e par :

\[
p\text{-valeur} = P(Y \geq -2\ln(LR)) \quad \text{avec } Y \sim \chi^2(d)
\]



### 3) Parametric Bootstrap

#### Introduction

Le parametric bootstrap est utilisÃ© lorsque la distribution de $\ln(LR)$ sous $H_0$ n'est pas connue. Une approximation empirique peut alors Ãªtre obtenue en gÃ©nÃ©rant des trajectoires simulÃ©es sous $H_0$.

#### Objectif

Nous cherchons Ã  comparer deux SMP (Semi Markov Process) et Ã  tester s'ils suivent la mÃªme loi.

#### MÃ©thodologie

1. Estimation du paramÃ¨tre $\theta$ par maximum de vraisemblance.
2. Calcul de la statistique de test observÃ©e avec les donnÃ©es rÃ©elles :
   $$
   T_0 = \ln(LR(S_1))
   $$
   - ConcrÃ¨tement, $T_0$ permet de dÃ©terminer si les donnÃ©es observÃ©es sont plus compatibles avec $H_0$ ou $H_1$.
3. GÃ©nÃ©ration de $R$ Ã©chantillons en supposant $H_0$ vraie avec les paramÃ¨tres estimÃ©s.
4. Calcul de la statistique de test pour chaque Ã©chantillon simulÃ© :
   $$
   T^* = \ln(LR(S^*))
   $$
   - Cela permet d'obtenir une distribution empirique de la statistique sous $H_0$.
5. Calcul de la p-valeur :
   $$
   p_{\text{boot}} = \frac{\#(T^* \leq T_0)}{R}
   $$
   - Si la p-valeur est plus petite qu'un seuil $\alpha$, alors on peut rejeter $H_0$.  
   - Cela signifie que les trajectoires des deux populations ne suivent pas la mÃªme loi.

#### InterprÃ©tation de la p-valeur

- Si $T_0$ est beaucoup plus grand que les $T^*$ â $H_0$ est suspect.
- Si $T_0$ est du mÃªme ordre de grandeur que les $T^*$ â $H_0$ est crÃ©dible.


#### Code R 

- PARAMETRIC BOOTSTRAP

```{r}
#On vient faire appel Ã  la fonction calculant la log-vraisemblance d'un ensemble de trajectoires d'un SMP

library(stats4)

estimate_mle <- function(param, trajectories, absorbing_state, dist_type) {
  
  alpha <- param$alpha
  P <- param$P
  omega <- param$omega

  mle <- mle(-log_likelihood, #On prend l'opposÃ© du likelihood car dans cette librairie, la fonction mle minimise
                 start = list(params),
                 fixed = list(param, trajectories, absorbing_state, 
                              dist_type),
                 method = "L-BFGS-B")

  return(mle)
}


#on vient gÃ©nÃ©rer un SMP suivant les paramÃ¨tres du MLE sous H0 :

generate_smp_trajectory <- function(params, absorbing_state, dist_type, max_transitions = n1+n2) {
  states <- numeric(max_transitions)
  times <- numeric(max_transitions)
  
  states[1] <- sample(1:length(params$alpha), 1, prob = params$alpha) 
  for (i in 1:(max_transitions - 1)) {
    current_state <- states[i]
    
    if (current_state == absorbing_state) break #stop  si Ã©tat absorbant
    
    states[i + 1] <- sample(1:nrow(params$P), 1, prob = params$P[current_state, ])
    
    if (dist_type == "gamma") {
      times[i] <- rgamma(1, shape = params$omega[[current_state]][1], rate = params$omega[[current_state]][2])
    } else if (dist_type == "weibull") {
      times[i] <- rweibull(1, shape = params$omega[[current_state]][1], scale = params$omega[[current_state]][2])
    }
  }
  
  return(list(states = states[1:(i + 1)], times = times[1:i]))
}


#On vient ensuite effectuer R fois ce processus en calculant la statistique de test Ã  chaque fois


#On vient ensuite effectuer R fois ce processus en calculant la statistique de test Ã  chaque fois

parametric_bootstrap <- function(trajectories, absorbing_state, dist_type, R) {
  
  # On calcule les paramÃ¨tres du MLE
  mle_params <- estimate_mle(trajectories, absorbing_state, dist_type)
  
  # Calcul de la statistique de test T_l A MODIFIER CAR NE FAIS PAS LE RAPPORT DE VRAISEMBLANCE, SIMPLE CALCUL SOUS H0 ICI
  T_l <- log_likelihood(mle_params, trajectories, absorbing_state, dist_type)
  
  # Compteur pour la p-value
  count <- 0
  for (r in 1:R) {
    
    # GÃ©nÃ©re n trajectoires indÃ©pendantes sous H0 avec les paramÃ¨tres du MLE
    bootstrap_trajectories <- lapply(1:length(trajectories), function(i) {
      generate_smp_trajectory(mle_params, absorbing_state, dist_type)
    })
    
    # Calcule la stat de test T* pour les trajectoires gÃ©nÃ©rÃ©es
    T_star <- log_likelihood(mle_params, bootstrap_trajectories, absorbing_state, dist_type)
    
    # ItÃ©rations pour le calcul de la p-value
    if (T_star <= T_l) {
      count <- count + 1
    }
  }
  
  p_boot <- count / R
  
  return(p_boot) #renvoie direct la p-value
}
