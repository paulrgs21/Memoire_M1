---
title: "Master's Thesis"
author: "Paul Rongieras, Valentin Rivet, Raphaël Capranico"
date: "2025-01-20"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
subtitle: >
  C. Frascola et al., 2022.
  Based on the article: "Two-Sample Tests for Semi-Markov Processes with 
  Parametric Sojourn Time Distributions: An Application in Sensory Analysis"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## I. Introduction

## II. Model and notations

### 1. Definition of a semi-Markov process

We define $(J_p)_{p \geq 1}$, a homogeneous Markov chain taking values in a finite state space $E$, with $D$ states and so $E = \{1, \ldots, D\}$. We denote its transition matrix $P$ by its generic elements $P_{lj} = \mathbb{P}(J_{p+1} = j \mid J_p = l)$ for all $j \neq l \in E$, and we suppose $P_{jj} = 0$ for all $j \in E$. We also define $(X_p)_{p \geq 1}$, the sequence of sojourn times in the visited states by the chain $(J_p)_{p \geq 1}$. For $j \neq l$, $\Phi_{lj}(t) = \mathbb{P}[X_p \leq t \mid J_p = l, J_{p+1} = j]$ is defined as the cumulative distribution function of the sojourn time given the current state of the chain and its next state.

The process $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process and satisfies the following Markov property for $t \in T = [0, +\infty)$, $j \neq l \in E$: 

$\mathbb{P}[J_{p+1} = j, X_p \leq t \mid J_p = l, J_{p-1}, \ldots, J_1, X_{p-1}, \ldots, X_1] = \mathbb{P}(J_{p+1} = j, X_p \leq t \mid J_p = l)$

as $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process. This can be rewritten as $\mathbb{P}(J_{p+1} = j \mid J_p = l) \cdot \mathbb{P}(X_p \leq t \mid J_{p+1} = j, J_p = l)$, using the formula $(i)$: 
$\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C)$, for any sets $A$, $B$, $C$. Thus: $P_{lj} \cdot \Phi_{lj}(t)$.

Proof of $(i)$: $\mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C) = \frac{\mathbb{P}(A \cap C)}{\mathbb{P}(C)} \cdot \frac{\mathbb{P}(B \cap A \cap C)}{\mathbb{P}(A \cap C)} = \frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)} = \mathbb{P}(A \cap B \mid C).$

The process giving the visited state at each time $t \in T$ is called a semi-Markov process. We then denote $\alpha = (\alpha_1, \ldots, \alpha_D)$ the vector of initial probabilities of the process, where $\alpha_j = \mathbb{P}(J_1 = j)$, $j \in E$.

We suppose that the distribution of the sojourn time is a parametric one, discrete or continuous, depending on a set of parameters denoted by $\omega \in \Omega \subset \mathbb{R}^q$. Thus, the law of a semi-Markov process (SMP) $(J_p, X_p)_{p \geq 1}$ can be characterised with the multidimensional parameter $\theta = (\alpha, P, (\omega_{l,j})_{l \neq j \in E}) \in \Theta$, where $\Theta$ is the parameter space. We denote by $\phi(t, \omega_{l,j})$ the probability (discrete time) or the density function (continuous time) of the distribution of the sojourn times for transitions between states $l$ and $j$, which is characterized by the vector of parameters $\omega = (\omega_{l,j})_{l \neq j \in E}$.

### 2. The Likelihood Given Observed Trajectories

As we consider a testing strategy based on the likelihood ratio $LR$, we have to define the likelihood of one Semi-Markov Process. To this purpose, we distinguish three different observation processes.

#### 2.1. A given number of transitions

\

First, each trajectory $S_i$ is observed during $M_i$ transitions, without censoring for the last sojourn time, so that $S_i = (J_1^{i},X_1^{i},...,J_{M_i}^{i},X_{M_i}^{i},J_{M_i+1}^{i},X_{M_i+1}^{i})$. Therefore, the likelihood corresponding to $S_i$ is equal to:

$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i+1}=J_{M_i+1}^{i},X_{M_i+1} \leq X_{M_i+1}^{i})$$
$$ = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = \mathbb{P}(J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i}|J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$  * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$ * \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}, J_{M_i+2} = j|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = P_{J_{M_i}^{i}J_{M_i+1}^{i}} \phi(X_{M_i}^{i},\omega_{J_{M_i}^{i},J_{M_i+1}^{i}}) * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
$$ = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
by applying Chapman-Kolmogorov repeatedly.

If we suppose that $\forall j \neq l, \omega_{l,j} = \omega_l$, we have the last term that becomes:
$$\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j}) = \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(J_{M_i+2} = j|J_{M_i+1}=J_{M_i+1}^{i}) * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_{M_i+1}=J_{M_i+1}^{i})$$
$$ = 1 * \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}}) = \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$
So in this case, the expression of the likelihood is simplified:
$$\mathcal{L}(S_i;\theta) = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i}}) *\phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$

#### 2.2. A given time for observation

\

The second supposition that we can make is that each sequence $S_i$ is observed over a period $[0,T_i]$ of time, so that the last sojourn time $u_{T_i}^{i}$ is censored. By denoting by $M_i(T_i)$ the number of visited states before instant $T_i$, the sequence $S_i$ is equal to $(J_1^{i},X_1^{i},...,J_{M_i(T_i)}^{i},u_{T_i}^{i})$. $\overline H_{J_{M_i(T_i)}}(t)$ describes the survival function for the last visited state of the trajectory $S_i$. For $l \in E, t>0$, we have:
$$\overline H_l^{i}(t) = \mathbb{P}(X_{M_i(T_i)}^{i}>t|J_{M_i(T_i)}^{i}=l) =1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l)$$
$$=1 -\sum_{\substack{j \in E,\ j \neq l}} \mathbb{P}(X_{M_i(T_i)}^{i} \leq t, J_{M_i(T_i)+1}^{i}=j|J_{M_i(T_i)}^{i}=l)$$
$$ =1 - \sum_{\substack{j \in E,\ j \neq l}} P_{lj} * \phi(t,\omega_{l,j})$$

We can define the likelihood of the trajectory $S_i$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i},X_{M_i(T_i)} \geq u_{T_i}^{i})$$
as the last sojourn time is censored,
$$=\mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i}) * \mathbb{P}(X_{M_i(T_i)} \geq u_{T_i}^{i} |J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i})$$
$$=\alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$$
$$ * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} \mathbb{P}\left( X_{M_i(T_i)} \leq u_{T_i}^{i},\ J_{M_i(T_i)+1}=j\ \middle|\ J_1=J_1^{i}, X_1 \leq X_1^{i}, \ldots, J_{M_i(T_i)}=J_{M_i(T_i)}^{i} \right)  \right)$$
by the result of 2.1.
$$= \alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} P_{J_{M_i(T_i)}^{i}j} \phi(u_{T_i}^{i}, \omega_{J_{M_i(T_i)}^{i}, j}) \right)$$
$$=\alpha_{J_1}^{i} * \left(\prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})\right) * \overline H_{J_{M_i(T_i)}^{i}}(u_{T_i}^{i})$$

We can note that when the sojourn time distribution only depends on the current state $l$, we have $\overline H_l^{i}(t) = 1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l) = 1 - \phi(t, \omega_l)$.

#### 2.3. Observation until absorption

\

If we consider that our processes may have an absorbing state, we suppose that we observe a trajectory $S_i$ until absorption. To simplify, we relabel the states such that the absorbing state is the last state D. It is assumed that the absorbing state can not be reached during the first transition so that $\alpha_D = \mathbb{P}(J_1=D)=0$, and $\Phi_{lj}(t)$ is only defined for $l \in E_{\setminus D},\ j \in E$ and $l \neq j$. By denoting by $M_i(D)$ the number of visited states before absorption, we can write the likelihood of a trajectory $S_i= (J_1^{i},X_1^{i},...,J_{M_i(D)}^{i},X_{M_i(D)}^{i},J_{M_i(D)+1}^{i}=D)$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(D)}=J_{M_i(D)}^{i},X_{M_i(D)} \leq X_{M_i(D)}^{i},J_{M_i(D)+1}=D)$$
$$= \mathbb P (J_{M_i(D)+1}=D, X_{M_i(D)} \leq X_{M_i(D)}^{i} | J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ * \mathbb P (J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i},D}) * \mathbb P (J_{M_i(D)}=J_{M_i(D)}^{i}, X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i} | ...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i}) $$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i}D}) * P_{J_{M_i(D)-1}^{i}J_{M_i(D)}^{i}} * \phi (X_{M_i(D)-1}^{i}, \omega_{J_{M_i(D)-1}^{i},M_{i(D)}^{i}})$$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$= \alpha_{J_1}^{i} * \phi(X_1^{i}, \omega_{J_1^{i},J_2^{i}}) * \left( \prod_{k=2}^{M_i(D)} P_{J_{k-1}^{i}J_k^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) \right) * P_{J_{M_i(D)}^{i}D}$$
by iterating.

To simplify future computations, we write:
$$\mathcal{L}(S_i;\theta) = \mathcal{L_1}(S_i;\alpha) * \mathcal{L_2}(S_i;\omega) * \mathcal{L_3}(S_i;P)$$
with $\mathcal{L_1}(S_i;\alpha) = \alpha_{J_1^{i}}$ ; $\mathcal{L_2}(S_i;\omega)= \prod_{k=1}^{M_i(D)} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$ and $\mathcal{L_3}(S_i;P)= \prod_{k=2}^{M_i(D)+1} P_{J_{k-1}^{i}J_k^{i}}$.

## III. Two samples hypothesis testing

### 1) Global likelihood ratio test

Construction du Likelihood Ratio

- Sous \(H_0\)

Par indépendance des observations \(S^1\) et \(S^2\), on peut maximiser la vraisemblance :

\[
\max_{\theta \in \Theta} \prod_{i=1}^{n1} l(S_i^1, \theta) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta)
\]

- Sous \(H_1\)

Cela devient :

\[
\max_{\theta_1 \in \Theta_1, \theta_2 \in \Theta_2} \prod_{i=1}^{n1} l(S_i^1, \theta_1) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta_2)
\]

On obtient bien le ratio de vraisemblance :

\[
LR = \frac{\text{vraisemblance sous } H_0}{\text{vraisemblance sous } H_1}
\]

### 2) Asymptotic distribution of -2ln(LR)


Pour calculer la p-valeur de notre test, on va montrer que :

\[
-2\ln(LR) \sim \chi^2(d)
\]

Soit \(\mathcal{l}(\theta)\) la log-vraisemblance, avec :

- \(\hat{\theta}\) : Estimateur du maximum de vraisemblance (MLE) de \(\theta\),
- \(\theta_0\) : Valeur de \(\theta\) sous \(H_0\).

Par développement en série de Taylor autour de \(\hat{\theta}\), sous les hypothèses de régularité permettant le développement :

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta}) + o(\|\theta - \hat{\theta}\|^2)
\]

Par définition du MLE, on sait que :

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

Cela implique que :

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta = \hat{\theta}}\right) (\theta_0 - \hat{\theta}) + o(\|\theta_0 - \hat{\theta}\|^2)
\]

Ou encore :

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]

Par la loi des grands nombres, sous des hypothèses de régularité assurant la convergence uniforme :

\[
\frac{1}{n} \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta_0} \right] = - I_{\theta_0}
\]

où \( I_{\theta_0} \) est l'information de Fisher évaluée en \(\theta_0\). On en déduit que :

\[
\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Donc :

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) + o(n\|\theta_0 - \hat{\theta}\|^2)
\]

Sous \(H_0\), l'estimateur du maximum de vraisemblance satisfait asymptotiquement :

\[
\sqrt{n} I_{\theta_0}^{1/2} (\hat{\theta} - \theta_0) \sim \mathcal{N}(0, I_d)
\]

où \( I_d \) est la matrice identité de taille \( d \), avec \( d \) égal à la différence entre le nombre de paramètres estimés sous \(H_1\) et \(H_0\). Cela découle du théorème central limite appliqué à l'estimateur du maximum de vraisemblance.

Cela implique que :

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

où \(d\) est la différence entre les paramètres estimés sous \(H_1\) et \(H_0\).


La p-valeur est alors donnée par :

\[
p\text{-valeur} = P(Y \geq -2\ln(LR)) \quad \text{avec } Y \sim \chi^2(d)
\]



## III. Two-Sample Hypothesis Testing

### 3.1 Global Likelihood Ratio Test

We aim to compare the laws of two Semi-Markov Processes (SMPs) using two independent samples of trajectories drawn from two different populations. Let the probability law of the SMP in the first population be characterized by \(\theta_1 = (\alpha^1, \mathbf{P}^1, (\omega_{\ell,j}^1)_{\ell,j \in E, j \neq \ell})\), and in the second population by \(\theta_2 = (\alpha^2, \mathbf{P}^2, (\omega_{\ell,j}^2)_{\ell,j \in E, j \neq \ell})\).

We consider the following hypothesis test:

\[
H_0: \theta_1 = \theta_2 \quad \text{vs} \quad H_1: \theta_1 \neq \theta_2
\]

Under the null hypothesis \(H_0\), we define \(\theta = \theta_1 = \theta_2 = (\alpha, \mathbf{P}, (\omega_{\ell,j})_{\ell,j \in E, j \neq \ell})\).

Suppose we observe \(n_1\) independent trajectories from the first population and \(n_2\) independent trajectories from the second population. For \(b \in \{1, 2\}\) and \(i = 1, \ldots, n_b\), let \(S_i^b\) denote the \(i\)-th observed trajectory from population \(b\). The pooled sample is denoted by \(S_n = (S_1^1, \ldots, S_{n_1}^1, S_{n_1+1}^2, \ldots, S_{n_1+n_2}^2)\).

The likelihood ratio test is based on the logarithm of the ratio between the maximum likelihood under \(H_0\) and the maximum likelihood under \(H_1\). By the independence assumption, the likelihood ratio (LR) can be expressed as:

\[
LR = \frac{\max_{\theta \in \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta) \right)}{\max_{(\theta_1, \theta_2) \in \Theta \times \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta_1) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta_2) \right)}
\]

Under \(H_0\), the trajectories from both populations are combined into a single dataset, as \(H_0\) assumes that both populations follow the same model. This combined dataset is used to estimate the parameters under the null hypothesis.

We reject the null hypothesis \(H_0\) for small values of the statistic \(LR\). For a given significance level \(\gamma \in (0, 1)\), we seek the critical value \(c_\gamma\) such that, under \(H_0\), \(\mathbb{P}_{H_0}[LR \leq c_\gamma] = \gamma\). The main challenge is to compute the \(p\)-value corresponding to the observed sample.

#### Log-Likelihood Computation
The log-likelihood is computed using the structure defined in Equation (4). For parametric distributions such as Gamma and Weibull, the functions `dgamma` and `dweibull` are used to evaluate the probability density functions. These distributions are chosen because they are flexible enough to model non-exponential sojourn times and are well-suited for the asymptotic properties of the likelihood ratio test. Additionally, the exponential distribution is also considered due to its simplicity and ease of numerical optimization.

#### Parameter Estimation
The parameters of the SMP are estimated using maximum likelihood estimation (MLE). Different numerical optimization methods are employed to maximize the log-likelihood:

- **`optimx`**: This method is fast and tests multiple optimization algorithms without requiring manual handling of constraints.
- **Newton-Raphson (`nlm` in R)**: This method converges quickly but may fail if the log-likelihood is too complex or if the initial parameter estimates are far from the true values.

### 3.2 Asymptotic Distribution of \(-2 \ln(LR)\)

The first approach to compute the \(p\)-value is based on the asymptotic distribution of the likelihood ratio test. Under general conditions, if \(H_0\) is true, and if \(n_1\) and \(n_2\) tend to infinity with \(n_1/(n_1 + n_2)\) tending to some constant \(a \in (0, 1)\), which means that \( n_1 \) and \( n_2 \) are of a relatively equivalent order of magnitude, then \(-2 \ln(LR)\) converges in distribution to a \(\chi^2(d)\) distribution, where \(d\) is the difference in the number of parameters estimated under \(H_1\) and \(H_0\).

In order to compute the p-value of our test, let's show that:

\[
-2\ln(LR) \sim \chi^2(d)
\]

Let \(\mathcal{l}(\theta)\) be the log-likelihood function, with:

- \(\hat{\theta}\): Maximum Likelihood Estimator (MLE) of \(\theta\),
- \(\theta_0\): Value of \(\theta\) under \(H_0\).

By performing a Taylor series expansion around \(\hat{\theta}\), under the regularity conditions that allow the expansion:

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta}) + o(\|\theta - \hat{\theta}\|^2)
\]

By definition of the MLE, we know that:

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

This implies that:

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta = \hat{\theta}}\right) (\theta_0 - \hat{\theta}) + o(\|\theta_0 - \hat{\theta}\|^2)
\]

Or equivalently:

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]

By the law of large numbers, under the regularity conditions ensuring uniform convergence:

\[
\frac{1}{n} \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta_0} \right] = - I_{\theta_0}
\]

where \( I_{\theta_0} \) is the Fisher information matrix evaluated at \(\theta_0\). We then deduce that:

\[
\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Thus:

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) + o(n\|\theta_0 - \hat{\theta}\|^2)
\]

Under \(H_0\), the maximum likelihood estimator asymptotically satisfies:

\[
\sqrt{n} I_{\theta_0}^{1/2} (\hat{\theta} - \theta_0) \sim \mathcal{N}(0, I_d)
\]

where \( I_d \) is the identity matrix of size \( d \), with \( d \) being the difference in the number of parameters estimated under \(H_1\) and \(H_0\). This follows from the central limit theorem applied to the maximum likelihood estimator.

This implies that:

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

where \(d\) is the difference in the number of estimated parameters under \(H_1\) and \(H_0\).

In our framework, the number of constrained parameters under \(H_0\) is:

\[
d = 
\begin{cases}
D^2 - D - 1 + |\omega| \times D(D - 1) & \text{without any absorbing state} \\
D^2 - 2D + |\omega| \times (D - 1)^2 & \text{when the last state is absorbing}
\end{cases}
\]

where \(|\omega| = 2\) for the Gamma and Weibull distributions, as these are two-parameter distributions. This choice is motivated by their flexibility in modeling non-exponential sojourn times and their suitability for the asymptotic properties of the likelihood ratio test. The exponential distribution is also included due to its simplicity in numerical optimization.

Let's explain clearly why we have this value of d : 

#### Without Absorbing States

We define \( d \) as follows:

\[
d = D^2 - D - 1 + |w| \times D (D-1)
\]

where:
- \( D^2 \) represents the number of possible combinations of transitioning from one state to another (i.e., the transition matrix of size \( D \times D \)).  
- \( -D \) accounts for the probability of remaining in the same state (since we are computing the residence times, staying in the same state is impossible).  
- \( -1 \) corresponds to the sum of the coefficients of each row of the matrix, which is equal to 1  
- \( |w| \times D (D-1) \) incorporates parameters related to sojourn times for all possible transitions between two different states (hence the term \( D-1 \)).  

#### With an Absorbing State

When an absorbing state is present, \( d \) is modified as:

\[
d = D^2 - 2D + |w| \times (D-1)^2
\]

where:
- \( D^2 \) remains the same.  
- \( -2D \) represents the removal from :  
  * \( D \) transitions to the same state.  
  * \( D \) transitions from the absorbing state.  
- \( |w| \times (D-1)^2 \) adjusts for sojourn times but only for the first \( (D-1) \) states.  

Finally, let \(T_l = \ln[LR(S_n)]\) be the logarithm of the likelihood ratio based on the pooled sample. The \(p\)-value of the test is defined as:

\[
p_{\text{asymp}} = \mathbb{P}[Y \geq -2T_l]
\]

where \(Y\) is a random variable with a \(\chi^2(d)\) distribution.


### 3.3 Parametric bootstrap

The parametric bootstrap is used when the distribution of $\ln(LR)$ under $H_0$ is unknown. In this case, an empirical approximation can be obtained by generating simulated trajectories under $H_0$.

### Objective

We aim to compare two **Semi-Markov Processes (SMPs)** and test whether they follow the same distribution.

### Methodology

1. Estimate the parameter $\theta$ using the **maximum likelihood estimation** (MLE).
2. Compute the observed test statistic using real data:
   $$
   T_0 = \ln(LR(S_1))
   $$
   - This statistic helps determine whether the observed data is more consistent with $H_0$ or $H_1$. A high value of $T_0$ makes $H_0$ more credible, and vice versa.
3. Generate $R$ samples assuming $H_0$ is true, using the estimated parameters.
4. Compute the test statistic for each simulated sample:
   $$
   T^* = \ln(LR(S^*))
   $$
   - This provides an empirical distribution of the test statistic under $H_0$.
5. Compute the **bootstrap p-value**:
   $$
   p_{\text{boot}} = \frac{\#(T^* \leq T_0)}{R}
   $$
   - If the p-value is smaller than a chosen threshold $\alpha$, we reject $H_0$.
   - This means the trajectories of the two populations do not follow the same distribution.

### Interpretation of the p-value

- If $T_0$ is very large, many values of $T^*$ will be smaller, so the p-value will be high → $H_0$ is reliable
- If $T_0$ is very small, only a few values of $T^*$ will be smaller, so the p-value will be very small → $H_0$ is unlikely.



### 3.4 Permutation Test

## Permutation Test

The permutation test is a method used when the distribution of the test statistic $\ln(LR)$ under the null hypothesis $H_0$ is unknown. Under $H_0$, we assume that the parameter $\Theta$ is the same for both populations. This means that there is no reason to keep the two groups separate. The permutation test works by randomly reordering the observed trajectories from both groups and comparing the observed test statistic \( T_l = \ln(LR(S_n)) \) to the values obtained from the permuted datasets.

In theory, there are \( \binom{n_1 + n_2}{n_1} \) possible permutations, corresponding to the different ways of assigning \( n_1 \) trajectories among the total of \( n_1 + n_2 \). However, this number becomes very large, even for small values of \( n_1 \) and \( n_2 \). To make the computation feasible, we limit the number of permutations to \( R \) randomly chosen samples.

### Methodology

The permutation test follows these five main steps:

1. **Grouping the trajectories**  
   All \( n_1 + n_2 \) trajectories from both groups are combined into a single dataset. This step ensures that under \( H_0 \), any trajectory could belong to either group.

2. **Computing the observed test statistic**  
   The test statistic is calculated using the original data:
   \[
   T_l = \ln(LR(S_n)).
   \]
   This statistic helps determine whether the observed data supports \( H_0 \) or \( H_1 \).

3. **Permuting the trajectories**  
   Since \( H_0 \) assumes that the group labels are arbitrary, we randomly shuffle the trajectories without replacement. We generate \( R \) new datasets where the trajectories are reassigned randomly:
   \[
   S_{\pi_n} = (S_{\pi(1)}^1, \dots, S_{\pi(n_1)}^1, S_{\pi(n_1+1)}^2, \dots, S_{\pi(n_1+n_2)}^2).
   \]
   Each permutation represents a possible reassignment under \( H_0 \).

4. **Computing the test statistic for each permutation**  
   For each permuted dataset, we compute the test statistic:
   \[
   T^* = \ln(LR(S_{\pi_n})).
   \]
   This process is repeated \( R \) times, producing an empirical distribution of \( \ln(LR) \) under \( H_0 \).

5. **Computing the permutation p-value**  
   The p-value is calculated by comparing the observed statistic \( T_l \) to the test statistics obtained from the permutations:
   \[
   p_{\text{perm}} = \frac{\#(T^* \leq T_l)}{R}.
   \]
   Here, \( \# \) represents the number of times \( T^* \) is smaller than or equal to \( T_l \). A small p-value suggests that \( H_0 \) is unlikely.


The interpretation of the p-value is straightforward. If \( T_l \) is very large, most \( T^* \) values will be smaller, leading to a large p-value, meaning that \( H_0 \) is reliable On the other hand, if \( T_l \) is very small, only a few \( T^* \) values will be smaller, resulting in a very small p-value, making \( H_0 \) less likely.

The choice of \( R \) is important. Under $H_0$, the trajectories are interchangeable between the groups, meaning that the test statistic \( T_l \) is randomly positioned among the \( R+1 \) values (the observed statistic plus the \( R \) permuted values). The permutation p-value, denoted as \( p_{\text{permutation}} \), is defined as the proportion of \( T_r^* \) values that are "at least as extreme" as \( T_l \). If we reject \( H_0 \) when the empirical p-value is smaller than a chosen threshold \( \gamma \), it can be shown that:

\[
\mathbb{P}\bigl(p_{\text{permutation}} \leq \gamma\bigr) = \frac{\lfloor R\gamma\rfloor + 1}{R + 1}.
\]

This means that the test level is slightly different from \( \gamma \), but it becomes very close to \( \gamma \) as \( R \) increases. For this reason, we typically choose \( R = 300 \) or more.
