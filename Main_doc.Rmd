---
title: "Master's Thesis"
author: "Paul Rongieras, Valentin Rivet, Raphaël Capranico"
date: "2025-01-20"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
subtitle: >
  C. Frascola et al., 2022.
  Based on the article: "Two-Sample Tests for Semi-Markov Processes with 
  Parametric Sojourn Time Distributions: An Application in Sensory Analysis"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## I. Introduction

## II. Model and notations

### 1. Definition of a semi-Markov process

We define $(J_p)_{p \geq 1}$, a homogeneous Markov chain taking values in a finite state space $E$, with $D$ states and so $E = \{1, \ldots, D\}$. We denote its transition matrix $P$ by its generic elements $P_{lj} = \mathbb{P}(J_{p+1} = j \mid J_p = l)$ for all $j \neq l \in E$, and we suppose $P_{jj} = 0$ for all $j \in E$. We also define $(X_p)_{p \geq 1}$, the sequence of sojourn times in the visited states by the chain $(J_p)_{p \geq 1}$. For $j \neq l$, $\Phi_{lj}(t) = \mathbb{P}[X_p \leq t \mid J_p = l, J_{p+1} = j]$ is defined as the cumulative distribution function of the sojourn time given the current state of the chain and its next state.

The process $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process and satisfies the following Markov property for $t \in T = [0, +\infty)$, $j \neq l \in E$: 

$\mathbb{P}[J_{p+1} = j, X_p \leq t \mid J_p = l, J_{p-1}, \ldots, J_1, X_{p-1}, \ldots, X_1] = \mathbb{P}(J_{p+1} = j, X_p \leq t \mid J_p = l)$

as $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process. This can be rewritten as $\mathbb{P}(J_{p+1} = j \mid J_p = l) \cdot \mathbb{P}(X_p \leq t \mid J_{p+1} = j, J_p = l)$, using the formula $(i)$: 
$\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C)$, for any sets $A$, $B$, $C$. Thus: $P_{lj} \cdot \Phi_{lj}(t)$.

Proof of $(i)$: $\mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C) = \frac{\mathbb{P}(A \cap C)}{\mathbb{P}(C)} \cdot \frac{\mathbb{P}(B \cap A \cap C)}{\mathbb{P}(A \cap C)} = \frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)} = \mathbb{P}(A \cap B \mid C).$

The process giving the visited state at each time $t \in T$ is called a semi-Markov process. We then denote $\alpha = (\alpha_1, \ldots, \alpha_D)$ the vector of initial probabilities of the process, where $\alpha_j = \mathbb{P}(J_1 = j)$, $j \in E$.

We suppose that the distribution of the sojourn time is a parametric one, discrete or continuous, depending on a set of parameters denoted by $\omega \in \Omega \subset \mathbb{R}^q$. Thus, the law of a semi-Markov process (SMP) $(J_p, X_p)_{p \geq 1}$ can be characterised with the multidimensional parameter $\theta = (\alpha, P, (\omega_{l,j})_{l \neq j \in E}) \in \Theta$, where $\Theta$ is the parameter space. We denote by $\phi(t, \omega_{l,j})$ the probability (discrete time) or the density function (continuous time) of the distribution of the sojourn times for transitions between states $l$ and $j$, which is characterized by the vector of parameters $\omega = (\omega_{l,j})_{l \neq j \in E}$.

### 2. The Likelihood Given Observed Trajectories

As we consider a testing strategy based on the likelihood ratio $LR$, we have to define the likelihood of one Semi-Markov Process. To this purpose, we distinguish three different observation processes.

#### 2.1. A given number of transitions

\

First, each trajectory $S_i$ is observed during $M_i$ transitions, without censoring for the last sojourn time, so that $S_i = (J_1^{i},X_1^{i},...,J_{M_i}^{i},X_{M_i}^{i},J_{M_i+1}^{i},X_{M_i+1}^{i})$. Therefore, the likelihood corresponding to $S_i$ is equal to:

$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i+1}=J_{M_i+1}^{i},X_{M_i+1} \leq X_{M_i+1}^{i})$$
$$ = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = \mathbb{P}(J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i}|J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$  * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$ * \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}, J_{M_i+2} = j|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = P_{J_{M_i}^{i}J_{M_i+1}^{i}} \phi(X_{M_i}^{i},\omega_{J_{M_i}^{i},J_{M_i+1}^{i}}) * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
$$ = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
by applying Chapman-Kolmogorov repeatedly.

If we suppose that $\forall j \neq l, \omega_{l,j} = \omega_l$, we have the last term that becomes:
$$\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j}) = \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(J_{M_i+2} = j|J_{M_i+1}=J_{M_i+1}^{i}) * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_{M_i+1}=J_{M_i+1}^{i})$$
$$ = 1 * \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}}) = \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$
So in this case, the expression of the likelihood is simplified:
$$\mathcal{L}(S_i;\theta) = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i}}) *\phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$

#### 2.2. A given time for observation

\

The second supposition that we can make is that each sequence $S_i$ is observed over a period $[0,T_i]$ of time, so that the last sojourn time $u_{T_i}^{i}$ is censored. By denoting by $M_i(T_i)$ the number of visited states before instant $T_i$, the sequence $S_i$ is equal to $(J_1^{i},X_1^{i},...,J_{M_i(T_i)}^{i},u_{T_i}^{i})$. $\overline H_{J_{M_i(T_i)}}(t)$ describes the survival function for the last visited state of the trajectory $S_i$. For $l \in E, t>0$, we have:
$$\overline H_l^{i}(t) = \mathbb{P}(X_{M_i(T_i)}^{i}>t|J_{M_i(T_i)}^{i}=l) =1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l)$$
$$=1 -\sum_{\substack{j \in E,\ j \neq l}} \mathbb{P}(X_{M_i(T_i)}^{i} \leq t, J_{M_i(T_i)+1}^{i}=j|J_{M_i(T_i)}^{i}=l)$$
$$ =1 - \sum_{\substack{j \in E,\ j \neq l}} P_{lj} * \phi(t,\omega_{l,j})$$

We can define the likelihood of the trajectory $S_i$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i},X_{M_i(T_i)} \geq u_{T_i}^{i})$$
as the last sojourn time is censored,
$$=\mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i}) * \mathbb{P}(X_{M_i(T_i)} \geq u_{T_i}^{i} |J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i})$$
$$=\alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$$
$$ * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} \mathbb{P}\left( X_{M_i(T_i)} \leq u_{T_i}^{i},\ J_{M_i(T_i)+1}=j\ \middle|\ J_1=J_1^{i}, X_1 \leq X_1^{i}, \ldots, J_{M_i(T_i)}=J_{M_i(T_i)}^{i} \right)  \right)$$
by the result of 2.1.
$$= \alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} P_{J_{M_i(T_i)}^{i}j} \phi(u_{T_i}^{i}, \omega_{J_{M_i(T_i)}^{i}, j}) \right)$$
$$=\alpha_{J_1}^{i} * \left(\prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})\right) * \overline H_{J_{M_i(T_i)}^{i}}(u_{T_i}^{i})$$

We can note that when the sojourn time distribution only depends on the current state $l$, we have $\overline H_l^{i}(t) = 1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l) = 1 - \phi(t, \omega_l)$.

#### 2.3. Observation until absorption

\

If we consider that our processes may have an absorbing state, we suppose that we observe a trajectory $S_i$ until absorption. To simplify, we relabel the states such that the absorbing state is the last state D. It is assumed that the absorbing state can not be reached during the first transition so that $\alpha_D = \mathbb{P}(J_1=D)=0$, and $\Phi_{lj}(t)$ is only defined for $l \in E_{\setminus D},\ j \in E$ and $l \neq j$. By denoting by $M_i(D)$ the number of visited states before absorption, we can write the likelihood of a trajectory $S_i= (J_1^{i},X_1^{i},...,J_{M_i(D)}^{i},X_{M_i(D)}^{i},J_{M_i(D)+1}^{i}=D)$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(D)}=J_{M_i(D)}^{i},X_{M_i(D)} \leq X_{M_i(D)}^{i},J_{M_i(D)+1}=D)$$
$$= \mathbb P (J_{M_i(D)+1}=D, X_{M_i(D)} \leq X_{M_i(D)}^{i} | J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ * \mathbb P (J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i},D}) * \mathbb P (J_{M_i(D)}=J_{M_i(D)}^{i}, X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i} | ...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i}) $$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i}D}) * P_{J_{M_i(D)-1}^{i}J_{M_i(D)}^{i}} * \phi (X_{M_i(D)-1}^{i}, \omega_{J_{M_i(D)-1}^{i},M_{i(D)}^{i}})$$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$= \alpha_{J_1}^{i} * \phi(X_1^{i}, \omega_{J_1^{i},J_2^{i}}) * \left( \prod_{k=2}^{M_i(D)} P_{J_{k-1}^{i}J_k^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) \right) * P_{J_{M_i(D)}^{i}D}$$
by iterating.

To simplify future computations, we write:
$$\mathcal{L}(S_i;\theta) = \mathcal{L_1}(S_i;\alpha) * \mathcal{L_2}(S_i;\omega) * \mathcal{L_3}(S_i;P)$$
with $\mathcal{L_1}(S_i;\alpha) = \alpha_{J_1^{i}}$ ; $\mathcal{L_2}(S_i;\omega)= \prod_{k=1}^{M_i(D)} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$ and $\mathcal{L_3}(S_i;P)= \prod_{k=2}^{M_i(D)+1} P_{J_{k-1}^{i}J_k^{i}}$.

## III. Two samples hypothesis testing

### 1) Global likelihood ratio test

Construction du Likelihood Ratio

- Sous \(H_0\)

Par indépendance des observations \(S^1\) et \(S^2\), on peut maximiser la vraisemblance :

\[
\max_{\theta \in \Theta} \prod_{i=1}^{n1} l(S_i^1, \theta) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta)
\]

- Sous \(H_1\)

Cela devient :

\[
\max_{\theta_1 \in \Theta_1, \theta_2 \in \Theta_2} \prod_{i=1}^{n1} l(S_i^1, \theta_1) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta_2)
\]

On obtient bien le ratio de vraisemblance :

\[
LR = \frac{\text{vraisemblance sous } H_0}{\text{vraisemblance sous } H_1}
\]

### 2) Asymptotic distribution of -2ln(LR)


Pour calculer la p-valeur de notre test, on va montrer que :

\[
-2\ln(LR) \sim \chi^2(d)
\]

Soit \(\mathcal{l}(\theta)\) la log-vraisemblance, avec :

- \(\hat{\theta}\) : Estimateur du maximum de vraisemblance (MLE) de \(\theta\),
- \(\theta_0\) : Valeur de \(\theta\) sous \(H_0\).

Par développement en série de Taylor autour de \(\hat{\theta}\), sous les hypothèses de régularité permettant le développement :

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta}) + o(\|\theta - \hat{\theta}\|^2)
\]

Par définition du MLE, on sait que :

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

Cela implique que :

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta = \hat{\theta}}\right) (\theta_0 - \hat{\theta}) + o(\|\theta_0 - \hat{\theta}\|^2)
\]

Ou encore :

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]

Par la loi des grands nombres, sous des hypothèses de régularité assurant la convergence uniforme :

\[
\frac{1}{n} \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta_0} \right] = - I_{\theta_0}
\]

où \( I_{\theta_0} \) est l'information de Fisher évaluée en \(\theta_0\). On en déduit que :

\[
\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Donc :

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) + o(n\|\theta_0 - \hat{\theta}\|^2)
\]

Sous \(H_0\), l'estimateur du maximum de vraisemblance satisfait asymptotiquement :

\[
\sqrt{n} I_{\theta_0}^{1/2} (\hat{\theta} - \theta_0) \sim \mathcal{N}(0, I_d)
\]

où \( I_d \) est la matrice identité de taille \( d \), avec \( d \) égal à la différence entre le nombre de paramètres estimés sous \(H_1\) et \(H_0\). Cela découle du théorème central limite appliqué à l'estimateur du maximum de vraisemblance.

Cela implique que :

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

où \(d\) est la différence entre les paramètres estimés sous \(H_1\) et \(H_0\).


La p-valeur est alors donnée par :

\[
p\text{-valeur} = P(Y \geq -2\ln(LR)) \quad \text{avec } Y \sim \chi^2(d)
\]



## III. Two-Sample Hypothesis Testing

### 3.1 Global Likelihood Ratio Test

We aim to compare the laws of two Semi-Markov Processes (SMPs) using two independent samples of trajectories drawn from two different populations. Let the probability law of the SMP in the first population be characterized by \(\theta_1 = (\alpha^1, \mathbf{P}^1, (\omega_{\ell,j}^1)_{\ell,j \in E, j \neq \ell})\), and in the second population by \(\theta_2 = (\alpha^2, \mathbf{P}^2, (\omega_{\ell,j}^2)_{\ell,j \in E, j \neq \ell})\).

We consider the following hypothesis test:

\[
H_0: \theta_1 = \theta_2 \quad \text{vs} \quad H_1: \theta_1 \neq \theta_2
\]

Under the null hypothesis \(H_0\), we define \(\theta = \theta_1 = \theta_2 = (\alpha, \mathbf{P}, (\omega_{\ell,j})_{\ell,j \in E, j \neq \ell})\).

Suppose we observe \(n_1\) independent trajectories from the first population and \(n_2\) independent trajectories from the second population. For \(b \in \{1, 2\}\) and \(i = 1, \ldots, n_b\), let \(S_i^b\) denote the \(i\)-th observed trajectory from population \(b\). The pooled sample is denoted by \(S_n = (S_1^1, \ldots, S_{n_1}^1, S_{n_1+1}^2, \ldots, S_{n_1+n_2}^2)\).

The likelihood ratio test is based on the logarithm of the ratio between the maximum likelihood under \(H_0\) and the maximum likelihood under \(H_1\). By the independence assumption, the likelihood ratio (LR) can be expressed as:

\[
LR = \frac{\max_{\theta \in \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta) \right)}{\max_{(\theta_1, \theta_2) \in \Theta \times \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta_1) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta_2) \right)}
\]

Under \(H_0\), the trajectories from both populations are combined into a single dataset, as \(H_0\) assumes that both populations follow the same model. This combined dataset is used to estimate the parameters under the null hypothesis.

We reject the null hypothesis \(H_0\) for small values of the statistic \(LR\). For a given significance level \(\gamma \in (0, 1)\), we seek the critical value \(c_\gamma\) such that, under \(H_0\), \(\mathbb{P}_{H_0}[LR \leq c_\gamma] = \gamma\). The main challenge is to compute the \(p\)-value corresponding to the observed sample.

#### Log-Likelihood Computation
The log-likelihood is computed using the structure defined in Equation (4). For parametric distributions such as Gamma and Weibull, the functions `dgamma` and `dweibull` are used to evaluate the probability density functions. These distributions are chosen because they are flexible enough to model non-exponential sojourn times and are well-suited for the asymptotic properties of the likelihood ratio test. Additionally, the exponential distribution is also considered due to its simplicity and ease of numerical optimization.

#### Parameter Estimation
The parameters of the SMP are estimated using maximum likelihood estimation (MLE). Different numerical optimization methods are employed to maximize the log-likelihood:

- **`optimx`**: This method is fast and tests multiple optimization algorithms without requiring manual handling of constraints.
- **Newton-Raphson (`nlm` in R)**: This method converges quickly but may fail if the log-likelihood is too complex or if the initial parameter estimates are far from the true values.

### 3.2 Asymptotic Distribution of \(-2 \ln(LR)\)

The first approach to compute the \(p\)-value is based on the asymptotic distribution of the likelihood ratio test. Under general conditions, if \(H_0\) is true, and if \(n_1\) and \(n_2\) tend to infinity with \(n_1/(n_1 + n_2)\) tending to some constant \(a \in (0, 1)\), then \(-2 \ln(LR)\) converges in distribution to a \(\chi^2(d)\) distribution, where \(d\) is the difference in the number of parameters estimated under \(H_1\) and \(H_0\).

In the context of Semi-Markov processes, the asymptotic distribution of \(-2 \ln(LR)\) has not been rigorously established under general assumptions. However, for Markov processes, similar results have been obtained for two-sample tests in both discrete and continuous time (Anderson and Goodman, 1957; Billingsley, 1961). For Semi-Markov processes, consistency and asymptotic normality of parameter estimators have been proven under weak conditions (Trevezas, 2011; Barbu et al., 2017).

In our framework, the number of constrained parameters under \(H_0\) is:

\[
d = 
\begin{cases}
D^2 - D - 1 + |\omega| \times D(D - 1) & \text{without any absorbing state} \\
D^2 - 2D + |\omega| \times (D - 1)^2 & \text{when the last state is absorbing}
\end{cases}
\]

where \(|\omega| = 2\) for the Gamma and Weibull distributions, as these are two-parameter distributions. This choice is motivated by their flexibility in modeling non-exponential sojourn times and their suitability for the asymptotic properties of the likelihood ratio test. The exponential distribution is also included due to its simplicity in numerical optimization.

Let \(T_l = \ln[LR(S_n)]\) be the logarithm of the likelihood ratio based on the pooled sample. The \(p\)-value of the test is defined as:

\[
p_{\text{asymp}} = \mathbb{P}[Y \geq -2T_l]
\]

where \(Y\) is a random variable with a \(\chi^2(d)\) distribution.

### 3.3 Parametric Bootstrap

The second approach to compute the \(p\)-value is based on the parametric bootstrap, which approximates the distribution of \(\ln(LR)\) under \(H_0\) by simulating trajectories under the null hypothesis.

Let \(\widehat{\theta}_l\) be the maximum likelihood estimator of \(\theta\) based on the pooled sample \(S_n\). The distribution of the test statistic \(\ln(LR)\) is approximated under \(H_0\) by generating \(n\) independent trajectories \(S_n^* = (S_1^{1^*}, \ldots, S_{n_1}^{1^*}, S_{n_1+1}^{2^*}, \ldots, S_{n_1+n_2}^{2^*})\) of an SMP with parameter \(\widehat{\theta}_l\). This procedure is repeated \(R\) times (typically \(R = 1000\)) to approximate the distribution of \(\ln(LR)\) under \(H_0\).

The \(p\)-value is then calculated as:

\[
p_{\text{boot}} = \frac{\#(T^* \leq T_l)}{R}
\]

where \(\#\) denotes the cardinality, and \(T^* = \ln[LR(S_n^*)]\) is the test statistic computed on the simulated samples.


### 3) Parametric Bootstrap

#### Introduction

Le parametric bootstrap est utilisé lorsque la distribution de $\ln(LR)$ sous $H_0$ n'est pas connue. Une approximation empirique peut alors être obtenue en générant des trajectoires simulées sous $H_0$.

#### Objectif

Nous cherchons à comparer deux SMP (Semi Markov Process) et à tester s'ils suivent la même loi.

#### Méthodologie

1. Estimation du paramètre $\theta$ par maximum de vraisemblance.
2. Calcul de la statistique de test observée avec les données réelles :
   $$
   T_0 = \ln(LR(S_1))
   $$
   - Concrètement, $T_0$ permet de déterminer si les données observées sont plus compatibles avec $H_0$ ou $H_1$ : une valeur de $T_0$ élevée rendra $H_0$ crédible, et inversement.
3. Génération de $R$ échantillons en supposant $H_0$ vraie avec les paramètres estimés.
4. Calcul de la statistique de test pour chaque échantillon simulé :
   $$
   T^* = \ln(LR(S^*))
   $$
   - Cela permet d'obtenir une distribution empirique de la statistique sous $H_0$.
5. Calcul de la p-valeur :
   $$
   p_{\text{boot}} = \frac{\#(T^* \leq T_0)}{R}
   $$
   - Si la p-valeur est plus petite qu'un seuil $\alpha$, alors on peut rejeter $H_0$.  
   - Cela signifie que les trajectoires des deux populations ne suivent pas la même loi.

#### Interprétation de la p-valeur

- Si $T_0$ est très grand, il y aura beucoup de $T^*$ plus petits donc la p-valeur sera assez grande → $H_0$ est crédible
- Si $T_0$ est très petit, il y aura peu de $T^*$ plus petits donc la p valeur sera très petite → $H_0$ est suspect


### Permutation Test

#### Introduction

Le test de permutation est une méthode utilisée lorsque la distribution de la statistique de test $\ln(LR)$ sous $H_0$ est inconnue. Si l'on suppose sous l'hypothèse nulle que notre paramètre Theta est le même pour les 2 populations, alors il n'y a plus d'intérêt à les diviser et le test de permutation va donc réorganiser aléatoirement les trajectoires observées des 2 groupes  comparer la statistique observée \( T_l = \ln(LR(S_n)) \) aux valeurs obtenues sous permutation des trajectoires.


En théorie, il existe \( \binom{n_1 + n_2}{n_1} \) permutations possibles, correspondant aux différentes manières de répartir \( n_1 \) trajectoires parmi \( n_1 + n_2 \). Cependant, ce nombre devient rapidement trop grand, même pour des faibles valeurs de \( n_1 \) et \( n_2 \).  

On se restreint donc à \( R \) permutations choisies de manière aléatoire.

-> Choix du nombre R

Sous \( H_0 \), les trajectoires sont interchangeables entre les groupes, ce qui signifie que la statistique \( T_l \) a une position aléatoire parmi les \( R+1 \) valeurs obtenues (la statistique observée et les \( R \) valeurs permutées).
Et on va construire la p-valeur de permutation \( p_{\text{permutation}} \) comme étant la proportion des \( T_r^* \) qui sont « au moins aussi extrêmes » que \( T_l \).


Ainsi, si l'on rejette \( H_0 \) lorsque la p-valeur empirique est inférieure à \( \gamma \), on peut montrer que :

\[\mathbb{P}\bigl(p_{\text{permutation}} \leq \gamma\bigr) = \frac{\lfloor R\gamma\rfloor + 1}{R + 1}.\]
Cela signifie que le test est de niveau légèrement différent de \( \gamma \). Mais qu'il s'en rapproche et que cet écart devient négligeable lorsque \( R \) est suffisamment grand.
C'est pour cela qu'on choisira une valeur de R égale à 1000.


#### Méthodologie

1. Regroupement  
   On regroupe les $n_1 + n_2$ trajectoires des deux groupes dans un même ensemble :  


2. Calcul de la statistique observée  
   On calcule la statistique de test $\ln(LR)$ sur les données réelles :
   \[
   T_l = \ln(LR(S_n))
   \]

3. Permutation des trajectoires  
   Sous $H_0$, l’appartenance à un groupe est arbitraire. On génère donc $R$ permutations des trajectoires, en mélangeant aléatoirement les observations sans replacement :
   \[
   S_{\pi_n} = (S_{\pi(1)}^1, \dots, S_{\pi(n_1)}^1, S_{\pi(n_1+1)}^2, \dots, S_{\pi(n_1+n_2)}^2)
   \]

4. Calcul de la statistique pour chaque permutation
   Pour chaque jeu de données permuté, on recalcule la statistique de test :
   \[
   T^* = \ln(LR(S_{\pi_n}))
   \]
   Cette étape est répétée $R$ fois pour obtenir une distribution empirique de $\ln(LR)$ sous $H_0$.

5. Calcul de la p-valeur  
   La p-valeur est obtenue en comparant la statistique observée $T_l$ aux statistiques issues des permutations :
   \[
   p_{\text{perm}} = \frac{\#(T^* \leq T_l)}{R}
   \]
   où $\#$ désigne le nombre de fois où $T^*$ est inférieur ou égal à $T_l$.

#### Interprétation de la p-valeur

- Si $T_l$ est très grand, il y aura beucoup de $T^*$ plus petits donc la p-valeur sera assez grande → $H_0$ est crédible
- Si $T_l$ est très petit, il y aura peu de $T^*$ plus petits donc la p valeur sera très petite → $H_0$ est suspect
