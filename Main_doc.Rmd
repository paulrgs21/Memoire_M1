---
title: "Master's Thesis"
author: "Paul Rongieras, Valentin Rivet, RaphaÃ«l Capranico"
date: "2025-01-20"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
subtitle: >
  C. Frascola et al., 2022.
  Based on the article: "Two-Sample Tests for Semi-Markov Processes with 
  Parametric Sojourn Time Distributions: An Application in Sensory Analysis"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## I. Introduction

## II. Model and notations

### 1. Definition of a semi-Markov process

We define $(J_p)_{p \geq 1}$, a homogeneous Markov chain taking values in a finite state space $E$, with $D$ states and so $E = \{1, \ldots, D\}$. We denote its transition matrix $P$ by its generic elements $P_{lj} = \mathbb{P}(J_{p+1} = j \mid J_p = l)$ for all $j \neq l \in E$, and we suppose $P_{jj} = 0$ for all $j \in E$. We also define $(X_p)_{p \geq 1}$, the sequence of sojourn times in the visited states by the chain $(J_p)_{p \geq 1}$. For $j \neq l$, $\Phi_{lj}(t) = \mathbb{P}[X_p \leq t \mid J_p = l, J_{p+1} = j]$ is defined as the cumulative distribution function of the sojourn time given the current state of the chain and its next state.

The process $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process and satisfies the following Markov property for $t \in T = [0, +\infty)$, $j \neq l \in E$: 

$\mathbb{P}[J_{p+1} = j, X_p \leq t \mid J_p = l, J_{p-1}, \ldots, J_1, X_{p-1}, \ldots, X_1] = \mathbb{P}(J_{p+1} = j, X_p \leq t \mid J_p = l)$

as $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process. This can be rewritten as $\mathbb{P}(J_{p+1} = j \mid J_p = l) \cdot \mathbb{P}(X_p \leq t \mid J_{p+1} = j, J_p = l)$, using the formula $(i)$: 
$\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C)$, for any sets $A$, $B$, $C$. Thus: $P_{lj} \cdot \Phi_{lj}(t)$.

Proof of $(i)$: $\mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C) = \frac{\mathbb{P}(A \cap C)}{\mathbb{P}(C)} \cdot \frac{\mathbb{P}(B \cap A \cap C)}{\mathbb{P}(A \cap C)} = \frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)} = \mathbb{P}(A \cap B \mid C).$

The process giving the visited state at each time $t \in T$ is called a semi-Markov process. We then denote $\alpha = (\alpha_1, \ldots, \alpha_D)$ the vector of initial probabilities of the process, where $\alpha_j = \mathbb{P}(J_1 = j)$, $j \in E$.

We suppose that the distribution of the sojourn time is a parametric one, discrete or continuous, depending on a set of parameters denoted by $\omega \in \Omega \subset \mathbb{R}^q$. Thus, the law of a semi-Markov process (SMP) $(J_p, X_p)_{p \geq 1}$ can be characterised with the multidimensional parameter $\theta = (\alpha, P, (\omega_{l,j})_{l \neq j \in E}) \in \Theta$, where $\Theta$ is the parameter space. We denote by $\phi(t, \omega_{l,j})$ the probability (discrete time) or the density function (continuous time) of the distribution of the sojourn times for transitions between states $l$ and $j$, which is characterized by the vector of parameters $\omega = (\omega_{l,j})_{l \neq j \in E}$.

### 2. The Likelihood Given Observed Trajectories

As we consider a testing strategy based on the likelihood ratio $LR$, we have to define the likelihood of one Semi-Markov Process. To this purpose, we distinguish three different observation processes.

#### 2.1. A given number of transitions

\

First, each trajectory $S_i$ is observed during $M_i$ transitions, without censoring for the last sojourn time, so that $S_i = (J_1^{i},X_1^{i},...,J_{M_i}^{i},X_{M_i}^{i},J_{M_i+1}^{i},X_{M_i+1}^{i})$. Therefore, the likelihood corresponding to $S_i$ is equal to:

$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i+1}=J_{M_i+1}^{i},X_{M_i+1} \leq X_{M_i+1}^{i})$$
$$ = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = \mathbb{P}(J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i}|J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$  * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$ * \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}, J_{M_i+2} = j|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = P_{J_{M_i}^{i}J_{M_i+1}^{i}} \phi(X_{M_i}^{i},\omega_{J_{M_i}^{i},J_{M_i+1}^{i}}) * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
$$ = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
by applying Chapman-Kolmogorov repeatedly.

If we suppose that $\forall j \neq l, \omega_{l,j} = \omega_l$, we have the last term that becomes:
$$\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j}) = \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(J_{M_i+2} = j|J_{M_i+1}=J_{M_i+1}^{i}) * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_{M_i+1}=J_{M_i+1}^{i})$$
$$ = 1 * \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}}) = \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$
So in this case, the expression of the likelihood is simplified:
$$\mathcal{L}(S_i;\theta) = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i}}) *\phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$

#### 2.2. A given time for observation

\

The second supposition that we can make is that each sequence $S_i$ is observed over a period $[0,T_i]$ of time, so that the last sojourn time $u_{T_i}^{i}$ is censored. By denoting by $M_i(T_i)$ the number of visited states before instant $T_i$, the sequence $S_i$ is equal to $(J_1^{i},X_1^{i},...,J_{M_i(T_i)}^{i},u_{T_i}^{i})$. $\overline H_{J_{M_i(T_i)}}(t)$ describes the survival function for the last visited state of the trajectory $S_i$. For $l \in E, t>0$, we have:
$$\overline H_l^{i}(t) = \mathbb{P}(X_{M_i(T_i)}^{i}>t|J_{M_i(T_i)}^{i}=l) =1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l)$$
$$=1 -\sum_{\substack{j \in E,\ j \neq l}} \mathbb{P}(X_{M_i(T_i)}^{i} \leq t, J_{M_i(T_i)+1}^{i}=j|J_{M_i(T_i)}^{i}=l)$$
$$ =1 - \sum_{\substack{j \in E,\ j \neq l}} P_{lj} * \phi(t,\omega_{l,j})$$

We can define the likelihood of the trajectory $S_i$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i},X_{M_i(T_i)} \geq u_{T_i}^{i})$$
as the last sojourn time is censored,
$$=\mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i}) * \mathbb{P}(X_{M_i(T_i)} \geq u_{T_i}^{i} |J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i})$$
$$=\alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$$
$$ * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} \mathbb{P}\left( X_{M_i(T_i)} \leq u_{T_i}^{i},\ J_{M_i(T_i)+1}=j\ \middle|\ J_1=J_1^{i}, X_1 \leq X_1^{i}, \ldots, J_{M_i(T_i)}=J_{M_i(T_i)}^{i} \right)  \right)$$
by the result of 2.1.
$$= \alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} P_{J_{M_i(T_i)}^{i}j} \phi(u_{T_i}^{i}, \omega_{J_{M_i(T_i)}^{i}, j}) \right)$$
$$=\alpha_{J_1}^{i} * \left(\prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})\right) * \overline H_{J_{M_i(T_i)}^{i}}(u_{T_i}^{i})$$

We can note that when the sojourn time distribution only depends on the current state $l$, we have $\overline H_l^{i}(t) = 1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l) = 1 - \phi(t, \omega_l)$.

#### 2.3. Observation until absorption

\

If we consider that our processes may have an absorbing state, we suppose that we observe a trajectory $S_i$ until absorption. To simplify, we relabel the states such that the absorbing state is the last state D. It is assumed that the absorbing state can not be reached during the first transition so that $\alpha_D = \mathbb{P}(J_1=D)=0$, and $\Phi_{lj}(t)$ is only defined for $l \in E_{\setminus D},\ j \in E$ and $l \neq j$. By denoting by $M_i(D)$ the number of visited states before absorption, we can write the likelihood of a trajectory $S_i= (J_1^{i},X_1^{i},...,J_{M_i(D)}^{i},X_{M_i(D)}^{i},J_{M_i(D)+1}^{i}=D)$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(D)}=J_{M_i(D)}^{i},X_{M_i(D)} \leq X_{M_i(D)}^{i},J_{M_i(D)+1}=D)$$
$$= \mathbb P (J_{M_i(D)+1}=D, X_{M_i(D)} \leq X_{M_i(D)}^{i} | J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ * \mathbb P (J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i},D}) * \mathbb P (J_{M_i(D)}=J_{M_i(D)}^{i}, X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i} | ...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i}) $$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i}D}) * P_{J_{M_i(D)-1}^{i}J_{M_i(D)}^{i}} * \phi (X_{M_i(D)-1}^{i}, \omega_{J_{M_i(D)-1}^{i},M_{i(D)}^{i}})$$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$= \alpha_{J_1}^{i} * \phi(X_1^{i}, \omega_{J_1^{i},J_2^{i}}) * \left( \prod_{k=2}^{M_i(D)} P_{J_{k-1}^{i}J_k^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) \right) * P_{J_{M_i(D)}^{i}D}$$
by iterating.

To simplify future computations, we write:
$$\mathcal{L}(S_i;\theta) = \mathcal{L_1}(S_i;\alpha) * \mathcal{L_2}(S_i;\omega) * \mathcal{L_3}(S_i;P)$$
with $\mathcal{L_1}(S_i;\alpha) = \alpha_{J_1^{i}}$ ; $\mathcal{L_2}(S_i;\omega)= \prod_{k=1}^{M_i(D)} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$ and $\mathcal{L_3}(S_i;P)= \prod_{k=2}^{M_i(D)+1} P_{J_{k-1}^{i}J_k^{i}}$.

## III. Two samples hypothesis testing

### 1) Global likelihood ratio test

Construction du Likelihood Ratio

- Sous \(H_0\)

Par indÃ©pendance des observations \(S^1\) et \(S^2\), on peut maximiser la vraisemblance :

\[
\max_{\theta \in \Theta} \prod_{i=1}^{n1} l(S_i^1, \theta) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta)
\]

- Sous \(H_1\)

Cela devient :

\[
\max_{\theta_1 \in \Theta_1, \theta_2 \in \Theta_2} \prod_{i=1}^{n1} l(S_i^1, \theta_1) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta_2)
\]

On obtient bien le ratio de vraisemblance :

\[
LR = \frac{\text{vraisemblance sous } H_0}{\text{vraisemblance sous } H_1}
\]

### 2) Asymptotic distribution of -2ln(LR)


Pour calculer la p-valeur de notre test, on va montrer que :

\[
-2\ln(LR) \sim \chi^2(d)
\]

Soit \(\mathcal{l}(\theta)\) la log-vraisemblance, avec :

- \(\hat{\theta}\) : Estimateur du maximum de vraisemblance (MLE) de \(\theta\),
- \(\theta_0\) : Valeur de \(\theta\) sous \(H_0\).

Par dÃ©veloppement en sÃ©rie de Taylor autour de \(\hat{\theta}\), sous les hypothÃ¨ses de rÃ©gularitÃ© permettant le dÃ©veloppement :

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta}) + o(\|\theta - \hat{\theta}\|^2)
\]

Par dÃ©finition du MLE, on sait que :

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

Cela implique que :

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta = \hat{\theta}}\right) (\theta_0 - \hat{\theta}) + o(\|\theta_0 - \hat{\theta}\|^2)
\]

Ou encore :

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]

Par la loi des grands nombres, sous des hypothÃ¨ses de rÃ©gularitÃ© assurant la convergence uniforme :

\[
\frac{1}{n} \frac{\partial^2 \mathcal{l}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \big|_{\theta_0} \right] = - I_{\theta_0}
\]

oÃ¹ \( I_{\theta_0} \) est l'information de Fisher Ã©valuÃ©e en \(\theta_0\). On en dÃ©duit que :

\[
\frac{\partial^2 \mathcal{l}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Donc :

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) + o(n\|\theta_0 - \hat{\theta}\|^2)
\]

Sous \(H_0\), l'estimateur du maximum de vraisemblance satisfait asymptotiquement :

\[
\sqrt{n} I_{\theta_0}^{1/2} (\hat{\theta} - \theta_0) \sim \mathcal{N}(0, I_d)
\]

oÃ¹ \( I_d \) est la matrice identitÃ© de taille \( d \), avec \( d \) Ã©gal Ã  la diffÃ©rence entre le nombre de paramÃ¨tres estimÃ©s sous \(H_1\) et \(H_0\). Cela dÃ©coule du thÃ©orÃ¨me central limite appliquÃ© Ã  l'estimateur du maximum de vraisemblance.

Cela implique que :

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

oÃ¹ \(d\) est la diffÃ©rence entre les paramÃ¨tres estimÃ©s sous \(H_1\) et \(H_0\).


La p-valeur est alors donnÃ©e par :

\[
p\text{-valeur} = P(Y \geq -2\ln(LR)) \quad \text{avec } Y \sim \chi^2(d)
\]



## III. Two-Sample Hypothesis Testing

### 3.1 Global Likelihood Ratio Test

We aim to compare the laws of two Semi-Markov Processes (SMPs) using two independent samples of trajectories drawn from two different populations. Let the probability law of the SMP in the first population be characterized by \(\theta_1 = (\alpha^1, \mathbf{P}^1, (\omega_{\ell,j}^1)_{\ell,j \in E, j \neq \ell})\), and in the second population by \(\theta_2 = (\alpha^2, \mathbf{P}^2, (\omega_{\ell,j}^2)_{\ell,j \in E, j \neq \ell})\).

We consider the following hypothesis test:

\[
H_0: \theta_1 = \theta_2 \quad \text{vs} \quad H_1: \theta_1 \neq \theta_2
\]

Under the null hypothesis \(H_0\), we define \(\theta = \theta_1 = \theta_2 = (\alpha, \mathbf{P}, (\omega_{\ell,j})_{\ell,j \in E, j \neq \ell})\).

Suppose we observe \(n_1\) independent trajectories from the first population and \(n_2\) independent trajectories from the second population. For \(b \in \{1, 2\}\) and \(i = 1, \ldots, n_b\), let \(S_i^b\) denote the \(i\)-th observed trajectory from population \(b\). The pooled sample is denoted by \(S_n = (S_1^1, \ldots, S_{n_1}^1, S_{n_1+1}^2, \ldots, S_{n_1+n_2}^2)\).

The likelihood ratio test is based on the logarithm of the ratio between the maximum likelihood under \(H_0\) and the maximum likelihood under \(H_1\). By the independence assumption, the likelihood ratio (LR) can be expressed as:

\[
LR = \frac{\max_{\theta \in \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta) \right)}{\max_{(\theta_1, \theta_2) \in \Theta \times \Theta} \left( \prod_{i=1}^{n_1} \mathcal{L}(S_i^1; \theta_1) \times \prod_{j=n_1+1}^{n_1+n_2} \mathcal{L}(S_j^2; \theta_2) \right)}
\]

Under \(H_0\), the trajectories from both populations are combined into a single dataset, as \(H_0\) assumes that both populations follow the same model. This combined dataset is used to estimate the parameters under the null hypothesis.

We reject the null hypothesis \(H_0\) for small values of the statistic \(LR\). For a given significance level \(\gamma \in (0, 1)\), we seek the critical value \(c_\gamma\) such that, under \(H_0\), \(\mathbb{P}_{H_0}[LR \leq c_\gamma] = \gamma\). The main challenge is to compute the \(p\)-value corresponding to the observed sample.

#### Log-Likelihood Computation
The log-likelihood is computed using the structure defined in Equation (4). For parametric distributions such as Gamma and Weibull, the functions `dgamma` and `dweibull` are used to evaluate the probability density functions. These distributions are chosen because they are flexible enough to model non-exponential sojourn times and are well-suited for the asymptotic properties of the likelihood ratio test. Additionally, the exponential distribution is also considered due to its simplicity and ease of numerical optimization.

#### Parameter Estimation
The parameters of the SMP are estimated using maximum likelihood estimation (MLE). Different numerical optimization methods are employed to maximize the log-likelihood:

- **`optimx`**: This method is fast and tests multiple optimization algorithms without requiring manual handling of constraints.
- **Newton-Raphson (`nlm` in R)**: This method converges quickly but may fail if the log-likelihood is too complex or if the initial parameter estimates are far from the true values.

### 3.2 Asymptotic Distribution of \(-2 \ln(LR)\)

The first approach to compute the \(p\)-value is based on the asymptotic distribution of the likelihood ratio test. Under general conditions, if \(H_0\) is true, and if \(n_1\) and \(n_2\) tend to infinity with \(n_1/(n_1 + n_2)\) tending to some constant \(a \in (0, 1)\), then \(-2 \ln(LR)\) converges in distribution to a \(\chi^2(d)\) distribution, where \(d\) is the difference in the number of parameters estimated under \(H_1\) and \(H_0\).

In the context of Semi-Markov processes, the asymptotic distribution of \(-2 \ln(LR)\) has not been rigorously established under general assumptions. However, for Markov processes, similar results have been obtained for two-sample tests in both discrete and continuous time (Anderson and Goodman, 1957; Billingsley, 1961). For Semi-Markov processes, consistency and asymptotic normality of parameter estimators have been proven under weak conditions (Trevezas, 2011; Barbu et al., 2017).

In our framework, the number of constrained parameters under \(H_0\) is:

\[
d = 
\begin{cases}
D^2 - D - 1 + |\omega| \times D(D - 1) & \text{without any absorbing state} \\
D^2 - 2D + |\omega| \times (D - 1)^2 & \text{when the last state is absorbing}
\end{cases}
\]

where \(|\omega| = 2\) for the Gamma and Weibull distributions, as these are two-parameter distributions. This choice is motivated by their flexibility in modeling non-exponential sojourn times and their suitability for the asymptotic properties of the likelihood ratio test. The exponential distribution is also included due to its simplicity in numerical optimization.

Let \(T_l = \ln[LR(S_n)]\) be the logarithm of the likelihood ratio based on the pooled sample. The \(p\)-value of the test is defined as:

\[
p_{\text{asymp}} = \mathbb{P}[Y \geq -2T_l]
\]

where \(Y\) is a random variable with a \(\chi^2(d)\) distribution.

### 3.3 Parametric Bootstrap

The second approach to compute the \(p\)-value is based on the parametric bootstrap, which approximates the distribution of \(\ln(LR)\) under \(H_0\) by simulating trajectories under the null hypothesis.

Let \(\widehat{\theta}_l\) be the maximum likelihood estimator of \(\theta\) based on the pooled sample \(S_n\). The distribution of the test statistic \(\ln(LR)\) is approximated under \(H_0\) by generating \(n\) independent trajectories \(S_n^* = (S_1^{1^*}, \ldots, S_{n_1}^{1^*}, S_{n_1+1}^{2^*}, \ldots, S_{n_1+n_2}^{2^*})\) of an SMP with parameter \(\widehat{\theta}_l\). This procedure is repeated \(R\) times (typically \(R = 1000\)) to approximate the distribution of \(\ln(LR)\) under \(H_0\).

The \(p\)-value is then calculated as:

\[
p_{\text{boot}} = \frac{\#(T^* \leq T_l)}{R}
\]

where \(\#\) denotes the cardinality, and \(T^* = \ln[LR(S_n^*)]\) is the test statistic computed on the simulated samples.


### 3) Parametric Bootstrap

#### Introduction

Le parametric bootstrap est utilisÃ© lorsque la distribution de $\ln(LR)$ sous $H_0$ n'est pas connue. Une approximation empirique peut alors Ãªtre obtenue en gÃ©nÃ©rant des trajectoires simulÃ©es sous $H_0$.

#### Objectif

Nous cherchons Ã  comparer deux SMP (Semi Markov Process) et Ã  tester s'ils suivent la mÃªme loi.

#### MÃ©thodologie

1. Estimation du paramÃ¨tre $\theta$ par maximum de vraisemblance.
2. Calcul de la statistique de test observÃ©e avec les donnÃ©es rÃ©elles :
   $$
   T_0 = \ln(LR(S_1))
   $$
   - ConcrÃ¨tement, $T_0$ permet de dÃ©terminer si les donnÃ©es observÃ©es sont plus compatibles avec $H_0$ ou $H_1$ : une valeur de $T_0$ Ã©levÃ©e rendra $H_0$ crÃ©dible, et inversement.
3. GÃ©nÃ©ration de $R$ Ã©chantillons en supposant $H_0$ vraie avec les paramÃ¨tres estimÃ©s.
4. Calcul de la statistique de test pour chaque Ã©chantillon simulÃ© :
   $$
   T^* = \ln(LR(S^*))
   $$
   - Cela permet d'obtenir une distribution empirique de la statistique sous $H_0$.
5. Calcul de la p-valeur :
   $$
   p_{\text{boot}} = \frac{\#(T^* \leq T_0)}{R}
   $$
   - Si la p-valeur est plus petite qu'un seuil $\alpha$, alors on peut rejeter $H_0$.  
   - Cela signifie que les trajectoires des deux populations ne suivent pas la mÃªme loi.

#### InterprÃ©tation de la p-valeur

- Si $T_0$ est trÃ¨s grand, il y aura beucoup de $T^*$ plus petits donc la p-valeur sera assez grande â $H_0$ est crÃ©dible
- Si $T_0$ est trÃ¨s petit, il y aura peu de $T^*$ plus petits donc la p valeur sera trÃ¨s petite â $H_0$ est suspect


### Permutation Test

#### Introduction

Le test de permutation est une mÃ©thode utilisÃ©e lorsque la distribution de la statistique de test $\ln(LR)$ sous $H_0$ est inconnue. Si l'on suppose sous l'hypothÃ¨se nulle que notre paramÃ¨tre Theta est le mÃªme pour les 2 populations, alors il n'y a plus d'intÃ©rÃªt Ã  les diviser et le test de permutation va donc rÃ©organiser alÃ©atoirement les trajectoires observÃ©es des 2 groupes  comparer la statistique observÃ©e \( T_l = \ln(LR(S_n)) \) aux valeurs obtenues sous permutation des trajectoires.


En thÃ©orie, il existe \( \binom{n_1 + n_2}{n_1} \) permutations possibles, correspondant aux diffÃ©rentes maniÃ¨res de rÃ©partir \( n_1 \) trajectoires parmi \( n_1 + n_2 \). Cependant, ce nombre devient rapidement trop grand, mÃªme pour des faibles valeurs de \( n_1 \) et \( n_2 \).  

On se restreint donc Ã  \( R \) permutations choisies de maniÃ¨re alÃ©atoire.

-> Choix du nombre R

Sous \( H_0 \), les trajectoires sont interchangeables entre les groupes, ce qui signifie que la statistique \( T_l \) a une position alÃ©atoire parmi les \( R+1 \) valeurs obtenues (la statistique observÃ©e et les \( R \) valeurs permutÃ©es).
Et on va construire la p-valeur de permutation \( p_{\text{permutation}} \) comme Ã©tant la proportion des \( T_r^* \) qui sont Â«â¯au moins aussi extrÃªmesâ¯Â» que \( T_l \).


Ainsi, si l'on rejette \( H_0 \) lorsque la p-valeur empirique est infÃ©rieure Ã  \( \gamma \), on peut montrer que :

\[\mathbb{P}\bigl(p_{\text{permutation}} \leq \gamma\bigr) = \frac{\lfloor R\gamma\rfloor + 1}{R + 1}.\]
Cela signifie que le test est de niveau lÃ©gÃ¨rement diffÃ©rent de \( \gamma \). Mais qu'il s'en rapproche et que cet Ã©cart devient nÃ©gligeable lorsque \( R \) est suffisamment grand.
C'est pour cela qu'on choisira une valeur de R Ã©gale Ã  1000.


#### MÃ©thodologie

1. Regroupement  
   On regroupe les $n_1 + n_2$ trajectoires des deux groupes dans un mÃªme ensemble :  


2. Calcul de la statistique observÃ©e  
   On calcule la statistique de test $\ln(LR)$ sur les donnÃ©es rÃ©elles :
   \[
   T_l = \ln(LR(S_n))
   \]

3. Permutation des trajectoires  
   Sous $H_0$, lâappartenance Ã  un groupe est arbitraire. On gÃ©nÃ¨re donc $R$ permutations des trajectoires, en mÃ©langeant alÃ©atoirement les observations sans replacement :
   \[
   S_{\pi_n} = (S_{\pi(1)}^1, \dots, S_{\pi(n_1)}^1, S_{\pi(n_1+1)}^2, \dots, S_{\pi(n_1+n_2)}^2)
   \]

4. Calcul de la statistique pour chaque permutation
   Pour chaque jeu de donnÃ©es permutÃ©, on recalcule la statistique de test :
   \[
   T^* = \ln(LR(S_{\pi_n}))
   \]
   Cette Ã©tape est rÃ©pÃ©tÃ©e $R$ fois pour obtenir une distribution empirique de $\ln(LR)$ sous $H_0$.

5. Calcul de la p-valeur  
   La p-valeur est obtenue en comparant la statistique observÃ©e $T_l$ aux statistiques issues des permutations :
   \[
   p_{\text{perm}} = \frac{\#(T^* \leq T_l)}{R}
   \]
   oÃ¹ $\#$ dÃ©signe le nombre de fois oÃ¹ $T^*$ est infÃ©rieur ou Ã©gal Ã  $T_l$.

#### InterprÃ©tation de la p-valeur

- Si $T_l$ est trÃ¨s grand, il y aura beucoup de $T^*$ plus petits donc la p-valeur sera assez grande â $H_0$ est crÃ©dible
- Si $T_l$ est trÃ¨s petit, il y aura peu de $T^*$ plus petits donc la p valeur sera trÃ¨s petite â $H_0$ est suspect
