---
title: "Master's Thesis"
author: "Paul Rongieras, Valentin Rivet, Raphaël Capranico"
date: "2025-01-20"
output:
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
  pdf_document:
    toc: true
    toc_depth: 3
    latex_engine: xelatex
subtitle: >
  C. Frascola et al., 2022.
  Based on the article: "Two-Sample Tests for Semi-Markov Processes with 
  Parametric Sojourn Time Distributions: An Application in Sensory Analysis"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

## I. Introduction

## II. Model and notations

### 1. Definition of a semi-Markov process

We define $(J_p)_{p \geq 1}$, a homogeneous Markov chain taking values in a finite state space $E$, with $D$ states and so $E = \{1, \ldots, D\}$. We denote its transition matrix $P$ by its generic elements $P_{lj} = \mathbb{P}(J_{p+1} = j \mid J_p = l)$ for all $j \neq l \in E$, and we suppose $P_{jj} = 0$ for all $j \in E$. We also define $(X_p)_{p \geq 1}$, the sequence of sojourn times in the visited states by the chain $(J_p)_{p \geq 1}$. For $j \neq l$, $\Phi_{lj}(t) = \mathbb{P}[X_p \leq t \mid J_p = l, J_{p+1} = j]$ is defined as the cumulative distribution function of the sojourn time given the current state of the chain and its next state.

The process $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process and satisfies the following Markov property for $t \in T = [0, +\infty)$, $j \neq l \in E$: 

$\mathbb{P}[J_{p+1} = j, X_p \leq t \mid J_p = l, J_{p-1}, \ldots, J_1, X_{p-1}, \ldots, X_1] = \mathbb{P}(J_{p+1} = j, X_p \leq t \mid J_p = l)$

as $(J_p, X_p)_{p \geq 1}$ is a Markov renewal process. This can be rewritten as $\mathbb{P}(J_{p+1} = j \mid J_p = l) \cdot \mathbb{P}(X_p \leq t \mid J_{p+1} = j, J_p = l)$, using the formula $(i)$: 
$\mathbb{P}(A \cap B \mid C) = \mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C)$, for any sets $A$, $B$, $C$. Thus: $P_{lj} \cdot \Phi_{lj}(t)$.

Proof of $(i)$: $\mathbb{P}(A \mid C) \cdot \mathbb{P}(B \mid A \cap C) = \frac{\mathbb{P}(A \cap C)}{\mathbb{P}(C)} \cdot \frac{\mathbb{P}(B \cap A \cap C)}{\mathbb{P}(A \cap C)} = \frac{\mathbb{P}(A \cap B \cap C)}{\mathbb{P}(C)} = \mathbb{P}(A \cap B \mid C).$

The process giving the visited state at each time $t \in T$ is called a semi-Markov process. We then denote $\alpha = (\alpha_1, \ldots, \alpha_D)$ the vector of initial probabilities of the process, where $\alpha_j = \mathbb{P}(J_1 = j)$, $j \in E$.

We suppose that the distribution of the sojourn time is a parametric one, discrete or continuous, depending on a set of parameters denoted by $\omega \in \Omega \subset \mathbb{R}^q$. Thus, the law of a semi-Markov process (SMP) $(J_p, X_p)_{p \geq 1}$ can be characterised with the multidimensional parameter $\theta = (\alpha, P, (\omega_{l,j})_{l \neq j \in E}) \in \Theta$, where $\Theta$ is the parameter space. We denote by $\phi(t, \omega_{l,j})$ the probability (discrete time) or the density function (continuous time) of the distribution of the sojourn times for transitions between states $l$ and $j$, which is characterized by the vector of parameters $\omega = (\omega_{l,j})_{l \neq j \in E}$.

### 2. The Likelihood Given Observed Trajectories

As we consider a testing strategy based on the likelihood ratio $LR$, we have to define the likelihood of one Semi-Markov Process. To this purpose, we distinguish three different observation processes.

#### 2.1. A given number of transitions

\

First, each trajectory $S_i$ is observed during $M_i$ transitions, without censoring for the last sojourn time, so that $S_i = (J_1^{i},X_1^{i},...,J_{M_i}^{i},X_{M_i}^{i},J_{M_i+1}^{i},X_{M_i+1}^{i})$. Therefore, the likelihood corresponding to $S_i$ is equal to:

$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i+1}=J_{M_i+1}^{i},X_{M_i+1} \leq X_{M_i+1}^{i})$$
$$ = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = \mathbb{P}(J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i}|J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$  * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i})$$
$$ * \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}, J_{M_i+2} = j|J_1=J_1^{i},X_1 \leq X_1^{i},..., J_{M_i+1}=J_{M_i+1}^{i},X_{M_i} \leq X_{M_i}^{i})$$
$$ = P_{J_{M_i}^{i}J_{M_i+1}^{i}} \phi(X_{M_i}^{i},\omega_{J_{M_i}^{i},J_{M_i+1}^{i}}) * \mathbb{P}(J_{M_i}=J_{M_i}^{i},...,J_1=J_1^{i},X_{M_i-1} \leq X_{M_i-1}^{i},...,X_1 \leq X_1^{i}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
$$ = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) *\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j})$$
by applying Chapman-Kolmogorov repeatedly.

If we suppose that $\forall j \neq l, \omega_{l,j} = \omega_l$, we have the last term that becomes:
$$\sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} P_{J_{M_i+1}^{i}j} \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i},j}) = \sum_{\substack{j \in E \\ j \neq J_{M_i+1}}} \mathbb{P}(J_{M_i+2} = j|J_{M_i+1}=J_{M_i+1}^{i}) * \mathbb{P}(X_{M_i+1} \leq X_{M_i+1}^{i}|J_{M_i+1}=J_{M_i+1}^{i})$$
$$ = 1 * \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}}) = \phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$
So in this case, the expression of the likelihood is simplified:
$$\mathcal{L}(S_i;\theta) = \alpha_{J_1}^{i} * \prod_{k=1}^{M_i} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i}}) *\phi(X_{M_i+1}^{i},\omega_{J_{M_i+1}^{i}})$$

#### 2.2. A given time for observation

\

The second supposition that we can make is that each sequence $S_i$ is observed over a period $[0,T_i]$ of time, so that the last sojourn time $u_{T_i}^{i}$ is censored. By denoting by $M_i(T_i)$ the number of visited states before instant $T_i$, the sequence $S_i$ is equal to $(J_1^{i},X_1^{i},...,J_{M_i(T_i)}^{i},u_{T_i}^{i})$. $\overline H_{J_{M_i(T_i)}}(t)$ describes the survival function for the last visited state of the trajectory $S_i$. For $l \in E, t>0$, we have:
$$\overline H_l^{i}(t) = \mathbb{P}(X_{M_i(T_i)}^{i}>t|J_{M_i(T_i)}^{i}=l) =1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l)$$
$$=1 -\sum_{\substack{j \in E,\ j \neq l}} \mathbb{P}(X_{M_i(T_i)}^{i} \leq t, J_{M_i(T_i)+1}^{i}=j|J_{M_i(T_i)}^{i}=l)$$
$$ =1 - \sum_{\substack{j \in E,\ j \neq l}} P_{lj} * \phi(t,\omega_{l,j})$$

We can define the likelihood of the trajectory $S_i$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i},X_{M_i(T_i)} \geq u_{T_i}^{i})$$
as the last sojourn time is censored,
$$=\mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i}) * \mathbb{P}(X_{M_i(T_i)} \geq u_{T_i}^{i} |J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(T_i)}=J_{M_i(T_i)}^{i})$$
$$=\alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$$
$$ * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} \mathbb{P}\left( X_{M_i(T_i)} \leq u_{T_i}^{i},\ J_{M_i(T_i)+1}=j\ \middle|\ J_1=J_1^{i}, X_1 \leq X_1^{i}, \ldots, J_{M_i(T_i)}=J_{M_i(T_i)}^{i} \right)  \right)$$
by the result of 2.1.
$$= \alpha_{J_1}^{i} * \prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) * \left( 1 - \sum_{\substack{j \in E,\\ j \neq J_{M_i(T_i)}^{i}}} P_{J_{M_i(T_i)}^{i}j} \phi(u_{T_i}^{i}, \omega_{J_{M_i(T_i)}^{i}, j}) \right)$$
$$=\alpha_{J_1}^{i} * \left(\prod_{k=1}^{M_i(T_i)-1} P_{J_k^{i}J_{k+1}^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})\right) * \overline H_{J_{M_i(T_i)}^{i}}(u_{T_i}^{i})$$

We can note that when the sojourn time distribution only depends on the current state $l$, we have $\overline H_l^{i}(t) = 1-\mathbb{P}(X_{M_i(T_i)}^{i} \leq t|J_{M_i(T_i)}^{i}=l) = 1 - \phi(t, \omega_l)$.

#### 2.3. Observation until absorption

\

If we consider that our processes may have an absorbing state, we suppose that we observe a trajectory $S_i$ until absorption. To simplify, we relabel the states such that the absorbing state is the last state D. It is assumed that the absorbing state can not be reached during the first transition so that $\alpha_D = \mathbb{P}(J_1=D)=0$, and $\Phi_{lj}(t)$ is only defined for $l \in E_{\setminus D},\ j \in E$ and $l \neq j$. By denoting by $M_i(D)$ the number of visited states before absorption, we can write the likelihood of a trajectory $S_i= (J_1^{i},X_1^{i},...,J_{M_i(D)}^{i},X_{M_i(D)}^{i},J_{M_i(D)+1}^{i}=D)$:
$$\mathcal{L}(S_i;\theta) = \mathbb{P}(J_1=J_1^{i},X_1 \leq X_1^{i},...,J_{M_i(D)}=J_{M_i(D)}^{i},X_{M_i(D)} \leq X_{M_i(D)}^{i},J_{M_i(D)+1}=D)$$
$$= \mathbb P (J_{M_i(D)+1}=D, X_{M_i(D)} \leq X_{M_i(D)}^{i} | J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ * \mathbb P (J_1=J_1^{i},X_1 \leq X_1^{i},...,X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i},J_{M_i(D)}=J_{M_i(D)}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i},D}) * \mathbb P (J_{M_i(D)}=J_{M_i(D)}^{i}, X_{M_i(D)-1} \leq X_{M_i(D)-1}^{i} | ...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i}) $$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$ = P_{J_{M_i(D)}^{i}D} * \phi (X_{M_i(D)}^{i}, \omega_{J_{M_i(D)}^{i}D}) * P_{J_{M_i(D)-1}^{i}J_{M_i(D)}^{i}} * \phi (X_{M_i(D)-1}^{i}, \omega_{J_{M_i(D)-1}^{i},M_{i(D)}^{i}})$$
$$ * \mathbb P(J_1=J_1^{i},...,J_{M_i(D)-1}=J_{M_i(D)-1}^{i},X_{M_i(D)-2} \leq X_{M_i(D)-2}^{i})$$
$$= \alpha_{J_1}^{i} * \phi(X_1^{i}, \omega_{J_1^{i},J_2^{i}}) * \left( \prod_{k=2}^{M_i(D)} P_{J_{k-1}^{i}J_k^{i}} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}}) \right) * P_{J_{M_i(D)}^{i}D}$$
by iterating.

To simplify future computations, we write:
$$\mathcal{L}(S_i;\theta) = \mathcal{L_1}(S_i;\alpha) * \mathcal{L_2}(S_i;\omega) * \mathcal{L_3}(S_i;P)$$
with $\mathcal{L_1}(S_i;\alpha) = \alpha_{J_1^{i}}$ ; $\mathcal{L_2}(S_i;\omega)= \prod_{k=1}^{M_i(D)} \phi(X_k^{i},\omega_{J_k^{i},J_{k+1}^{i}})$ and $\mathcal{L_3}(S_i;P)= \prod_{k=2}^{M_i(D)+1} P_{J_{k-1}^{i}J_k^{i}}$.

## III. Two samples hypothesis testing

### 1) Global likelihood ratio test

Construction du Likelihood Ratio

- Sous \(H_0\)

Par indépendance des observations \(S^1\) et \(S^2\), on peut maximiser la vraisemblance :

\[
\max_{\theta \in \Theta} \prod_{i=1}^{n1} l(S_i^1, \theta) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta)
\]

- Sous \(H_1\)

Cela devient :

\[
\max_{\theta_1 \in \Theta_1, \theta_2 \in \Theta_2} \prod_{i=1}^{n1} l(S_i^1, \theta_1) \times \prod_{j=1}^{n1+n2} l(S_j^2, \theta_2)
\]

On obtient bien le ratio de vraisemblance :

\[
LR = \frac{\text{vraisemblance sous } H_0}{\text{vraisemblance sous } H_1}
\]

### 2) Asymptotic distribution of -2ln(LR)


Pour calculer la p-valeur de notre test, on va montrer que :

\[
-2\ln(LR) \sim \chi^2(d)
\]



Soit \(\mathcal{l}(\theta)\) la log-vraisemblance, avec :

- \(\hat{\theta}\) : Estimateur du maximum de vraisemblance (MLE) de \(\theta\),
- \(\theta_0\) : Valeur de \(\theta\) sous \(H_0\).

Par développement en série de Taylor autour de \(\hat{\theta}\) :

\[
\mathcal{l}(\theta) = \mathcal{l}(\hat{\theta}) + \frac{\partial \mathcal{l}}{\partial \theta} (\theta - \hat{\theta}) + \frac{1}{2} (\theta - \hat{\theta})^\top \frac{\partial^2 \mathcal{l}}{\partial \theta^2} (\theta - \hat{\theta})
\]

Par définition du MLE, on sait que :

\[
\frac{\partial \mathcal{l}}{\partial \theta} \big|_{\theta = \hat{\theta}} = 0
\]

Cela implique que :

\[
2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = (\theta_0 - \hat{\theta})^\top \left(- \frac{\partial^2 \mathcal{l}}{\partial \theta^2}\right) (\theta_0 - \hat{\theta})
\]

Ou encore :

\[
-2[\mathcal{l}(\theta_0) - \mathcal{l}(\hat{\theta})] = -2\ln\left(\frac{\mathcal{L}(\theta_0)}{\mathcal{L}(\hat{\theta})}\right) = -2\ln(LR)
\]


Par la loi des grands nombres :

\[
\frac{1}{n} \frac{\partial^2 \mathcal{L}}{\partial \theta^2} \to E\left[\frac{\partial^2 \mathcal{L}}{\partial \theta^2}\right]
\]

Alors, en utilisant l'information de Fisher \(I_{\theta_0}\) :

\[
\frac{\partial^2 \mathcal{L}}{\partial \theta^2} \approx -n I_{\theta_0}
\]

Donc :

\[
-2\ln(LR) = (\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta})
\]


Sous \(H_0\), on sait que :

\[
\sqrt{n} I_{\theta_0}^{1/2} (\theta_0 - \hat{\theta}) \sim \mathcal{N}(0, I)
\]

Cela implique que :

\[
(\theta_0 - \hat{\theta})^\top n I_{\theta_0} (\theta_0 - \hat{\theta}) \sim \chi^2(d)
\]

où \(d\) est la différence entre les paramètres estimés sous \(H_1\) et \(H_0\).


La p-valeur est alors donnée par :

\[
p\text{-valeur} = P(Y \geq -2\ln(LR)) \quad \text{avec } Y \sim \chi^2(d)
\]



### 3) Parametric Bootstrap

#### Introduction

Le parametric bootstrap est utilisé lorsque la distribution de $\ln(LR)$ sous $H_0$ n'est pas connue. Une approximation empirique peut alors être obtenue en générant des trajectoires simulées sous $H_0$.

#### Objectif

Nous cherchons à comparer deux SMP (Semi Markov Process) et à tester s'ils suivent la même loi.

#### Méthodologie

1. Estimation du paramètre $\theta$ par maximum de vraisemblance.
2. Calcul de la statistique de test observée avec les données réelles :
   $$
   T_0 = \ln(LR(S_1))
   $$
   - Concrètement, $T_0$ permet de déterminer si les données observées sont plus compatibles avec $H_0$ ou $H_1$.
3. Génération de $R$ échantillons en supposant $H_0$ vraie avec les paramètres estimés.
4. Calcul de la statistique de test pour chaque échantillon simulé :
   $$
   T^* = \ln(LR(S^*))
   $$
   - Cela permet d'obtenir une distribution empirique de la statistique sous $H_0$.
5. Calcul de la p-valeur :
   $$
   p_{\text{boot}} = \frac{\#(T^* \leq T_0)}{R}
   $$
   - Si la p-valeur est plus petite qu'un seuil $\alpha$, alors on peut rejeter $H_0$.  
   - Cela signifie que les trajectoires des deux populations ne suivent pas la même loi.

#### Interprétation de la p-valeur

- Si $T_0$ est beaucoup plus grand que les $T^*$ → $H_0$ est suspect.
- Si $T_0$ est du même ordre de grandeur que les $T^*$ → $H_0$ est crédible.


#### Code R 

- PARAMETRIC BOOTSTRAP

```{r}
#On vient faire appel à la fonction calculant la log-vraisemblance d'un ensemble de trajectoires d'un SMP

library(stats4)

estimate_mle <- function(param, trajectories, absorbing_state, dist_type) {
  
  alpha <- param$alpha
  P <- param$P
  omega <- param$omega

  mle <- mle(-log_likelihood, #On prend l'opposé du likelihood car dans cette librairie, la fonction mle minimise
                 start = list(params),
                 fixed = list(param, trajectories, absorbing_state, 
                              dist_type),
                 method = "L-BFGS-B")

  return(mle)
}


#on vient générer un SMP suivant les paramètres du MLE sous H0 :

generate_smp_trajectory <- function(params, absorbing_state, dist_type, max_transitions = n1+n2) {
  states <- numeric(max_transitions)
  times <- numeric(max_transitions)
  
  states[1] <- sample(1:length(params$alpha), 1, prob = params$alpha) 
  for (i in 1:(max_transitions - 1)) {
    current_state <- states[i]
    
    if (current_state == absorbing_state) break #stop  si état absorbant
    
    states[i + 1] <- sample(1:nrow(params$P), 1, prob = params$P[current_state, ])
    
    if (dist_type == "gamma") {
      times[i] <- rgamma(1, shape = params$omega[[current_state]][1], rate = params$omega[[current_state]][2])
    } else if (dist_type == "weibull") {
      times[i] <- rweibull(1, shape = params$omega[[current_state]][1], scale = params$omega[[current_state]][2])
    }
  }
  
  return(list(states = states[1:(i + 1)], times = times[1:i]))
}


#On vient ensuite effectuer R fois ce processus en calculant la statistique de test à chaque fois


#On vient ensuite effectuer R fois ce processus en calculant la statistique de test à chaque fois

parametric_bootstrap <- function(trajectories, absorbing_state, dist_type, R) {
  
  # On calcule les paramètres du MLE
  mle_params <- estimate_mle(trajectories, absorbing_state, dist_type)
  
  # Calcul de la statistique de test T_l A MODIFIER CAR NE FAIS PAS LE RAPPORT DE VRAISEMBLANCE, SIMPLE CALCUL SOUS H0 ICI
  T_l <- log_likelihood(mle_params, trajectories, absorbing_state, dist_type)
  
  # Compteur pour la p-value
  count <- 0
  for (r in 1:R) {
    
    # Génére n trajectoires indépendantes sous H0 avec les paramètres du MLE
    bootstrap_trajectories <- lapply(1:length(trajectories), function(i) {
      generate_smp_trajectory(mle_params, absorbing_state, dist_type)
    })
    
    # Calcule la stat de test T* pour les trajectoires générées
    T_star <- log_likelihood(mle_params, bootstrap_trajectories, absorbing_state, dist_type)
    
    # Itérations pour le calcul de la p-value
    if (T_star <= T_l) {
      count <- count + 1
    }
  }
  
  p_boot <- count / R
  
  return(p_boot) #renvoie direct la p-value
}
